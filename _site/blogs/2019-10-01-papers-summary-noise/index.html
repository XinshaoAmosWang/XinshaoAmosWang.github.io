<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v8.5.2 <https://hydejack.com/>
--><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><title>Paper Summary on Noise, Anomalies, Adversaries, Robust Learning, Generalization | Xinshao Wang</title><meta name="generator" content="Jekyll v3.8.6" /><meta property="og:title" content="Paper Summary on Noise, Anomalies, Adversaries, Robust Learning, Generalization" /><meta name="author" content="Xinshao Wang" /><meta property="og:locale" content="en" /><meta name="description" content="“Welcome to my personal website”. 3rd Year PhD Student, will graduate in Sep 2020." /><meta property="og:description" content="“Welcome to my personal website”. 3rd Year PhD Student, will graduate in Sep 2020." /><link rel="canonical" href="https://xinshaowang.com/blogs/2019-10-01-papers-summary-noise/" /><meta property="og:url" content="https://xinshaowang.com/blogs/2019-10-01-papers-summary-noise/" /><meta property="og:site_name" content="Xinshao Wang" /><meta property="og:image" content="https://xinshaowang.com/assets/img/blog/steve-harvey.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-10-01T00:00:00+01:00" /> <script type="application/ld+json"> {"description":"“Welcome to my personal website”. 3rd Year PhD Student, will graduate in Sep 2020.","author":{"@type":"Person","name":"Xinshao Wang"},"@type":"BlogPosting","url":"https://xinshaowang.com/blogs/2019-10-01-papers-summary-noise/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://xinshaowang.com/assets/icons/android-chrome-192x192.png"},"name":"Xinshao Wang"},"image":"https://xinshaowang.com/assets/img/blog/steve-harvey.jpg","headline":"Paper Summary on Noise, Anomalies, Adversaries, Robust Learning, Generalization","dateModified":"2019-10-01T00:00:00+01:00","datePublished":"2019-10-01T00:00:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://xinshaowang.com/blogs/2019-10-01-papers-summary-noise/"},"@context":"https://schema.org"}</script><meta name="keywords" content="Xinshao Wang; Machine Learning,Computer Vision,Robust Learning,Deep Metric Learning,Image Recognition,Video Recognition,Person ReID"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Xinshao Wang"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="application-name" content="Xinshao Wang"><meta name="msapplication-config" content="/assets/ieconfig.xml"><meta name="theme-color" content="rgb(25,55,71)"><meta name="generator" content="Hydejack v8.5.2" /><link type="application/atom+xml" rel="alternate" href="https://xinshaowang.com/feed.xml" title="Xinshao Wang" /><link rel="alternate" href="https://xinshaowang.com/blogs/2019-10-01-papers-summary-noise/" hreflang="en"><link rel="shortcut icon" href="/assets/icons/icon.png"><link rel="apple-touch-icon" href="/assets/icons/icon.png"><link rel="manifest" href="/assets/manifest.json"><link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="dns-prefetch" href="/" id="_baseURL"><link rel="dns-prefetch" href="/sw.js" id="_hrefSW"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.js" id="_hrefKatexJS"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.css" id="_hrefKatexCSS"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/contrib/copy-tex.min.js" id="_hrefKatexCopyJS"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/contrib/copy-tex.min.css" id="_hrefKatexCopyCSS"><link rel="dns-prefetch" href="/assets/img/swipe.svg" id="_hrefSwipeSVG"> <script> !function(e,t){"use strict";function n(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}e.loadJS=function(e,o){var r=t.createElement("script");r.src=e,o&&n(r,"load",o,{once:!0});var a=t.scripts[0];return a.parentNode.insertBefore(r,a),r},e._loaded=!1,e.loadJSDeferred=function(o,r){function a(){e._loaded=!0,r&&n(c,"load",r,{once:!0});var o=t.scripts[0];o.parentNode.insertBefore(c,o)}var c=t.createElement("script");return c.src=o,e._loaded?a():n(e,"load",a,{once:!0}),c},e.setRel=e.setRelStylesheet=function(e){function o(){this.rel="stylesheet"}n(t.getElementById(e),"load",o,{once:!0})}}(window,document); ; !function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this); ; !function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this); ; !function(w, d) { w._noPushState = false; w._noDrawer = false; }(window, document); </script> <!--[if gt IE 8]><!----><style> body{--code-font-family: Menlo,Monaco,Consolas,monospace;--font-weight: 400;--font-weight-bold: 700;--font-weight-heading: 400;--text-muted: #888;--gray-bg: rgba(0,0,0,0.025);--gray-text: #666;--menu-text: #bbb;--body-color: #333;--body-bg: #fff;--border-color: #ebebeb}.clearfix,.sidebar-social::after{content:"";display:table;clear:both}.color-transition,body,p,hr,.hr,table:not(.highlight) td,table:not(.highlight) th,.message{transition:background-color 1s ease, border-color 1s ease}.no-color-transition{transition:none !important}*{box-sizing:border-box}html,body{margin:0;padding:0}html{font-size:16px;line-height:1.75}body{color:var(--body-color);background-color:var(--body-bg);font-weight:var(--font-weight);overflow-y:scroll}a{text-decoration:none}.lead{margin-left:-1rem;margin-right:-1rem}.content img,.img,.content video,.video{max-width:100%}.content img.lead,.img.lead,.content video.lead,.video.lead{max-width:calc(100% + 2rem);width:calc(100% + 2rem)}h1,h2,h3,h4,h5,h6,.h1,.h2,.h3,.h4,.h5,.h6{font-weight:var(--font-weight-heading);margin:5rem 0 1rem}h1,.h1{font-size:2rem;line-height:1.3}h2,.h2{font-size:1.5rem;line-height:1.4}h3,.h3{font-size:1.17em;line-height:1.5}h4,h5,h6,.h4,.h5,.h6{font-size:1rem;margin-bottom:0.5rem}p{margin-top:0;margin-bottom:1rem}p.lead{font-size:1.2em;margin-top:1.5rem;margin-bottom:1.5rem;padding:0 1rem}ul,ol,dl{margin-top:0;margin-bottom:1rem}ul,ol{padding-left:1.25rem}hr{position:relative;margin:3rem 0;border:0;border-top:1px solid var(--border-color)}.hr{border-bottom:1px solid var(--border-color);padding-bottom:1rem;margin-bottom:2rem}table:not(.highlight){border-collapse:collapse;margin-bottom:2rem;margin-left:-1rem}table:not(.highlight) td,table:not(.highlight) th{padding:.25rem .5rem;border:1px solid var(--border-color)}table:not(.highlight) td:first-child,table:not(.highlight) th:first-child{padding-left:1rem}table:not(.highlight) td:last-child,table:not(.highlight) th:last-child{padding-right:1rem}.page{margin-bottom:3em}.page li+li{margin-top:.25rem}.page>header{margin-bottom:2rem}.page-title,.post-title{margin-top:0}.post-date{display:block;margin-top:-0.5rem;margin-bottom:1rem;color:var(--text-muted)}.related-posts{padding-left:0;list-style:none;margin-bottom:2rem}.related-posts>li,.related-posts>li+li{margin-top:1rem}.message{margin-bottom:1rem;padding:1rem;color:var(--gray-text);background-color:var(--gray-bg);margin-left:-1rem;margin-right:-1rem}@media screen{body::before{content:'';width:.5rem;background:var(--border-color);position:fixed;left:0;top:0;bottom:0}}@media screen and (min-width: 64em){body::before{width:21rem}}@media screen and (min-width: 1666px){body::before{width:calc(50% - 28rem)}}@media screen and (min-width: 42em){html{font-size:17px}}@media screen and (min-width: 124em){html{font-size:18px}}.fade-in{animation-duration:500ms;animation-timing-function:ease;animation-name:fade-in;animation-fill-mode:forwards}@keyframes fade-in{from{transform:translateY(-3rem);opacity:0}50%{transform:translateY(-3rem);opacity:0}to{transform:translateY(0);opacity:1}}.fl{float:left}.fr{float:right}.mb4{margin-bottom:4rem}.mb6{margin-bottom:6rem}.mt0{margin-top:0}.mt2{margin-top:2rem}.mt3{margin-top:3rem}.mt4{margin-top:4rem}.pb0{padding-bottom:0}.sixteen-nine{position:relative}.sixteen-nine::before{display:block;content:"";width:100%;padding-top:56.25%}.sixteen-nine>*{position:absolute;top:0;left:0;right:0;bottom:0}.sr-only{display:none}.border{border:1px solid var(--border-color)}hy-push-state a,.a{position:relative;padding-bottom:.15rem;border-bottom:1px solid}hy-push-state a.no-hover,.a.no-hover{border-bottom:none;padding-bottom:0}.content .img{overflow:hidden}.content .img img{margin:0;width:100%;height:100%;background-color:var(--gray-bg)}hy-drawer{width:100%;position:relative;overflow:hidden}@media screen and (min-width: 64em){hy-drawer{position:fixed;width:21rem;top:0;left:0;bottom:0;margin-left:0}hy-drawer.cover{position:relative;width:100%}}@media screen and (min-width: 1666px){hy-drawer{width:calc(50% - 28rem)}}.sidebar{position:relative;display:flex;justify-content:center;align-items:center;color:rgba(255,255,255,0.75);text-align:center;z-index:2;min-height:100vh}.sidebar a{color:#fff;border-bottom-color:rgba(255,255,255,0.2)}.sidebar-bg{position:absolute;top:0;left:calc(50% - 50vw);width:100vw;height:100%;background:#202020 center / cover}.sidebar-bg::after{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background:rgba(0,0,0,0.05)}.sidebar-bg.sidebar-overlay::after{background:linear-gradient(to bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 50%, rgba(32,32,32,0) 100%)}.sidebar-sticky{position:relative;z-index:3;max-width:21rem;padding:1.5rem;contain:content}.sidebar-about .avatar{margin-bottom:1.5rem}.sidebar-about>h2{margin-top:0}.sidebar-nav>ul{list-style:none;padding-left:0}a.sidebar-nav-item{display:inline-block;font-weight:var(--font-weight-heading);line-height:1.75;padding:.25rem;border-bottom:1px solid rgba(255,255,255,0.2)}.sidebar-social>ul{display:inline-block;list-style:none;padding-left:0;margin-bottom:0}.sidebar-social>ul>li{float:left}.sidebar-social>ul>li>a{display:inline-block;text-align:center;font-size:1.4rem;width:3rem;height:4rem;padding:.5rem 0;line-height:3rem}.sidebar-social>ul li+li{margin-top:0}.fixed-common,.fixed-top,.fixed-bottom{position:fixed;left:0;width:100%;z-index:2}.fixed-top{top:0}.fixed-bottom{bottom:0}.navbar>.content{padding-top:0;padding-bottom:0;min-height:0;color:var(--menu-text)}.nav-btn-bar{margin:0 -1rem 0 -.875rem}.nav-btn{background:none;border:none;padding:1.75rem .875rem;color:var(--menu-text) !important;cursor:pointer}.animation-main{opacity:0;pointer-events:none}.content{position:relative;margin-left:auto;margin-right:auto;padding:6rem 1rem 12rem}@media screen{.content{padding-left:1.5rem;max-width:38rem;min-height:100vh}}@media screen and (min-width: 54em){.content{max-width:42rem}}@media screen and (min-width: 64em){.content{padding-left:1rem;margin-left:24rem;margin-right:3rem}}@media screen and (min-width: 88em){.content{margin-left:25rem;margin-right:4rem;max-width:48rem}}@media screen and (min-width: 1666px){.content{margin:auto}}.avatar{width:6.5rem;height:6.5rem;border-radius:100%;overflow:hidden}@media screen and (min-width: 88em){.avatar{width:7rem;height:7rem}}.content .avatar{float:right;margin-left:.5rem}html{font-family:Noto Sans,Helvetica,Arial,sans-serif}h1,h2,h3,h4,h5,h6,.h1,.h2,.h3,.h4,.h5,.h6,.heading{font-family:Roboto Slab,Helvetica,Arial,sans-serif}</style><link rel="preload" as="style" href="/assets/css/hydejack-8.5.2.css" id="_stylePreload"><link rel="preload" as="style" href="/assets/icomoon/style.css" id="_iconsPreload"><link rel="preload" as="style" href="https://fonts.googleapis.com/css?family=Roboto+Slab:400|Noto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload"> <script>setRel('_stylePreload');setRel('_iconsPreload');/**/setRel('_fontsPreload');/**/</script> <noscript><link rel="stylesheet" href="/assets/css/hydejack-8.5.2.css"><link rel="stylesheet" href="/assets/icomoon/style.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:400|Noto+Sans:400,400i,700,700i&display=swap"> </noscript><style id="_pageStyle"> .content a:not(.btn){color:#4fb1ba;border-color:rgba(79,177,186,0.2)}.content a:not(.btn):hover{border-color:#4fb1ba}:focus{outline-color:#4fb1ba !important}.btn-primary{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:focus,.btn-primary.focus,.form-control:focus,.form-control.focus{box-shadow:0 0 0 3px rgba(79,177,186,0.5)}.btn-primary:hover,.btn-primary.hover{color:#fff;background-color:#409ba3;border-color:#409ba3}.btn-primary:disabled,.btn-primary.disabled{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:active,.btn-primary.active{color:#fff;background-color:#409ba3;border-color:#409ba3}::selection{color:#fff;background:#4fb1ba}::-moz-selection{color:#fff;background:#4fb1ba}</style><!--<![endif]--><body class="no-color-transition"><div id="_navbar" class="navbar fixed-top"><div class="content"><div class="nav-btn-bar"> <span class="sr-only">Jump to:</span> <a id="_menu" class="nav-btn no-hover fl" href="#_navigation"> <span class="sr-only">Navigation</span> <span class="icon-menu"></span> </a>
</div></div></div><hr class="sr-only" hidden> <hy-push-state replace-ids="_main" link-selector="a[href]:not([href*='/assets/']):not(.external):not(.no-push-state)" duration="250" script-selector="script:not([type^='math/tex'])" prefetch><main id="_main" class="content fade-in layout-post" role="main" data-color="rgb(79,177,186)" data-theme-color="rgb(25,55,71)" data-image="/assets/img/sidebar-bg.jpg" data-overlay><article id="post-blogs-papers-summary-noise" class="page post mb6" role="article"><header><h1 class="post-title"> Paper Summary on Noise, Anomalies, Adversaries, Robust Learning, Generalization</h1>
<p class="post-date heading"> <time datetime="2019-10-01T00:00:00+01:00">01 Oct 2019</time> in <a href="/blogs/" class="flip-title">Blogs</a></p>
<div class="img lead sixteen-nine"> <hy-img src="/assets/img/blog/steve-harvey.jpg" alt="Paper Summary on Noise, Anomalies, Adversaries, Robust Learning, Generalization" root-margin="512px"> <noscript><img data-ignore src="/assets/img/blog/steve-harvey.jpg" alt="Paper Summary on Noise, Anomalies, Adversaries, Robust Learning, Generalization"></noscript> <span class="loading" slot="loading" hidden> <span class="icon-cog"></span> </span> </hy-img>
</div></header><p class="message"><img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> means being highly related to my personal research interest.</p>
<h2 id="iccv-2019-on-label-noise-">ICCV 2019 on label noise, …</h2>
<ul class="message">
<li>
<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Han_Deep_Self-Learning_From_Noisy_Labels_ICCV_2019_paper.pdf">Deep Self-Learning From Noisy Labels</a>: The proposed SMP trains in an iterative manner which contains two phases: the first phase is to train a network with <strong>the original noisy label and corrected label</strong> generated in the second phase.</li>
<li>
<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Co-Mining_Deep_Face_Recognition_With_Noisy_Labels_ICCV_2019_paper.pdf">Co-Mining: Deep Face Recognition With Noisy Labels</a>: We propose a novel <strong>co-mining</strong> framework, which employs two peer networks to <strong>detect the noisy faces, exchanges the high-confidence clean faces and reweights the clean faces</strong> in a mini-batch fashion.</li>
<li>
<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Kim_NLNL_Negative_Learning_for_Noisy_Labels_ICCV_2019_paper.pdf">NLNL: Negative Learning for Noisy Labels</a>: Input image belongs to this label–Positive Learning; Negative Learning (NL)–CNNs are trained using a complementary label as in “input image does not belong to this complementary label.”</li>
<li>
<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Symmetric_Cross_Entropy_for_Robust_Learning_With_Noisy_Labels_ICCV_2019_paper.pdf">Symmetric Cross Entropy for Robust Learning With Noisy Labels</a>: Already compared in our method.</li>
<li>
<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_O2U-Net_A_Simple_Noisy_Label_Detection_Approach_for_Deep_Neural_ICCV_2019_paper.pdf">O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks</a>: It only requires adjusting the hyper-parameters of the deep network to make its status transfer from overfitting to underfitting (O2U) cyclically. The losses of each sample are recorded during iterations. The higher the normalized average loss of a sample, the higher the probability of being noisy labels.</li>
</ul>
<h2 id="1-neurips-2019-meta-weight-net-learning-an-explicit-mapping-for-sample-weighting">
<img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> <a href="https://papers.nips.cc/paper/8467-meta-weight-net-learning-an-explicit-mapping-for-sample-weighting">NeurIPS 2019-Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting</a>
</h2>
<ul class="message">
<li>Targted problems: (1) Corrupted Labels (2) Class imbalance</li>
<li>Methodology: Guided by <strong>a small amount of unbiased meta-data</strong>, to learn an explicit weighting layer which takes training losses as input and outputs examples’ weights.</li>
<li>Code: <a href="https://github.com/xjtushujun/meta-weight-net">https://github.com/xjtushujun/meta-weight-net</a>
</li>
<li>
<strong>Introduciton: Why are the targeted problems important?</strong> In practice, however, such biased training data are commonly encountered. For instance, practically collected training samples always contain corrupted labels [10, 11, 12, 13, 14, 15, 16, 17]. A typical example is a dataset roughly collected from a crowdsourcing system [18] or search engines [19, 20], which would possibly yield a large amount of noisy labels. Another popular type of biased training data is those with class imbalance. Real-world datasets are usually depicted as skewed distributions, with a long-tailed configuration. A few classes account for most of the data, while most classes are under-represented. Effective learning with these biased training data, which is regarded to be biased from evaluation/test ones, is thus an important while challenging issue in machine learning [1, 21].</li>
<li>There exist <strong>two entirely contradictive ideas for constructing such a loss-weight mapping:</strong><ul>
<li>
<strong>Emphasise on harder ones:</strong> Enforce the learning to more emphasize samples with larger loss values since they are more like to be uncertain hard samples located on the classification boundary. Typical methods of this category include AdaBoost [22, 23], hard negative mining [24] and focal loss [25]. <strong>This sample weighting manner is known to be necessary for class imbalance problems, since it can prioritize the minority class with relatively higher training losses.</strong>
</li>
<li>
<strong>Emphasise on easier ones:</strong> The rationality lies on that these samples are more likely to be high-confident ones with clean labels. Typical methods include self-paced learning(SPL) [26], iterative reweighting [27, 17] and multiple variants [28, 29, 30]. This weighting strategy has been especially used in noisy label cases, since it inclines to suppress the effects of samples with extremely large loss values, possibly with corrupted incorrect labels.</li>
<li>
<strong>Deficiencies:</strong><ul>
<li>How about the case that the training set is both imbalanced and noisy.</li>
<li>They inevitably involve hyper-parameters, to be manually preset or tuned by cross-validation.</li>
</ul>
</li>
</ul>
</li>
<li>Experiments of this work:<ul>
<li>Class Imbalance Experiments<ul><li>ResNet-32 on long-tailed CIFAR-10 and CIFAR-100.</li></ul>
</li>
<li>Corrupted Label Experiments on CIFAR-10 and CIFAR-100<ul>
<li>WRN-28-10 with varying noise rates under uniform noise.</li>
<li>ResNet-32 with varying noise rates under flip noise - non-uniform noise.</li>
</ul>
</li>
<li>Real-world data-Clothing 1M with ResNet-50<ul><li>We use the 7k clean data as the meta dataset.</li></ul>
</li>
</ul>
</li>
<li>Problems of this work:<ul>
<li>For <strong>the case where the training set is both imbalanced and noisy</strong>, the authors mentioned in the introduction section that conventional methods cannot address this case. However, there is no experiment to demontrate that this method works.</li>
<li>Conventional methods inevitably involve hyper-parameters to tune by cross-validation. However, for the proposed method, <strong>unbiased meta-data is required, which is a more expensive hyper-factor</strong> in practice. Tuning hyper-parameters is cheaper than collecting unbiased meta-data for training the weighting function.</li>
</ul>
</li>
</ul>
<h2 id="1-icml-2019-better-generalization-with-less-data-using-robust-gradient-descent">
<img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> <a href="http://proceedings.mlr.press/v97/holland19a/holland19a.pdf">ICML 2019-Better generalization with less data using robust gradient descent</a>
</h2>
<h2 id="gan-adversary-examples-adversary-machine-learning"><a href="/my_docs/adversary/">GAN, Adversary Examples, Adversary Machine Learning</a></h2>
<h2 id="label-noise"><a href="/my_docs/Label-Noise/">Label Noise</a></h2>
<ul class="message">
<li>NeurIPS 2019-L_DMI: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise</li>
<li>NeurIPS 2019-Are Anchor Points Really Indispensable in Label-Noise Learning?</li>
<li>NeurIPS 2019-Combinatorial Inference against Label Noise</li>
</ul>
<h2 id="1--neurips-2019-noise-tolerant-fair-classification">
<img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> <a href="https://arxiv.org/abs/1901.10837">NeurIPS 2019-Noise-tolerant fair classification</a>
</h2>
<p class="message"><strong>NOTE</strong>: Existing work on the problem operates <strong>under the assumption that the sensitive feature available in one’s training sample is perfectly reliable.</strong> This assumption may be violated in many real-world cases: for example, respondents to a survey may choose to conceal or obfuscate their group identity out of fear of potential discrimination. This poses the question of whether one can still learn fair classifiers given noisy sensitive features.</p>
<h2 id="neurips-2019-neural-networks-grown-and-self-organized-by-noise"><a href="https://arxiv.org/abs/1906.01039">NeurIPS 2019-Neural networks grown and self-organized by noise</a></h2>
<p class="message"><strong>NOTE</strong>: <strong>Living neural networks</strong> emerge through a process of growth and self-organization that begins with a single cell and results in a brain, an organized and functional computational device. Artificial neural networks, however, rely on human-designed, hand-programmed architectures for their remarkable performance. <strong>Can we develop artificial computational devices that can grow and self-organize without human intervention?</strong> In this paper, we propose a biologically inspired developmental algorithm that can <strong>‘grow’ a functional, layered neural network from a single initial cell.</strong> The algorithm organizes inter-layer connections to construct a convolutional pooling layer, a key constituent of convolutional neural networks (CNN’s). Our approach is inspired by the mechanisms employed by the early visual system to wire the retina to the lateral geniculate nucleus (LGN), days before animals open their eyes. The key ingredients for robust self-organization are an emergent spontaneous spatiotemporal activity wave in the first layer and a local learning rule in the second layer that ‘learns’ the underlying activity pattern in the first layer. The algorithm is adaptable to a wide-range of input-layer geometries, robust to malfunctioning units in the first layer, and so can be used to <strong>successfully grow and self-organize pooling architectures of different pool-sizes and shapes.</strong> The algorithm provides a primitive procedure for constructing layered neural networks through growth and self-organization. Broadly, our work shows that biologically inspired developmental algorithms can be applied to autonomously grow functional ‘brains’ in-silico.</p>
<h2 id="stochastic-gradient-noise"><a href="/my_docs/Stochastic-Gradient-Noise/">Stochastic-Gradient-Noise</a></h2>
<ul class="message">
<li>ICML 2019-A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks</li>
<li>NeurIPS 2019-First Exit Time Analysis of Stochastic Gradient Descent Under Heavy-Tailed Gradient Noise</li>
</ul>
<h2 id="denoiser-noise-removal"><a href="/my_docs/Denoiser/">Denoiser, Noise Removal</a></h2>
<ul class="message">
<li>NeurIPS 2019-Extending Stein’s unbiased risk estimator to train deep denoisers with correlated pairs of noisy images</li>
<li>NeurIPS 2019-Variational Denoising Network: Toward Blind Noise Modeling and Removal</li>
</ul></article><hr class="dingbat related"> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], inlineMath: [['$','$'], ['\\(','\\)']], processEscapes: true }, TeX: { equationNumbers: { autoNumber: "AMS" } } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"> </script><div class="navigator"> <span style="float:left"><a href="/blogs/2019-10-01-papers-summary-metric/">« Paper Summary on Distance Metric, Representation Learning</a> · <a href="https://xinshaoamoswang.github.io/blogs/2019-10-01-papers-summary-metric/#disqus_thread"></a> </span> <span style="float:right"><a href="/projects/2019-10-01-PhD-3rd-start/">Start 3rd year (the final year of my PhD) »</a> · <a href="https://xinshaoamoswang.github.io/projects/2019-10-01-PhD-3rd-start/#disqus_thread"></a> </span>
</div>
<footer role="contentinfo"><hr>
<p><small class="copyright">© 2019. All rights reserved. </small></p>
<p><small>Welcome to Xinshao Wang's Personal Website</small></p>
<hr class="sr-only"></footer></main><hy-drawer class="" align="left" threshold="10" touch-events prevent-default><header id="_sidebar" class="sidebar" role="banner"><div class="sidebar-bg sidebar-overlay" style="background-color:rgb(25,55,71);background-image:url(/assets/img/sidebar-bg.jpg)"></div>
<div class="sidebar-sticky">
<div class="sidebar-about"> <a class="no-hover" href="/" tabindex="-1"> <img src="/assets/icons/android-chrome-192x192.png" class="avatar" alt="Xinshao Wang" data-ignore> </a><h2 class="h1"><a href="/">Xinshao Wang</a></h2>
<p class="fine"> Machine Learning (Deep Metric Learning, Robust Learning under Arbitrary Anomalies). Computer Vision (Image/Video Recognition, Person ReID).</p>
</div>
<nav class="sidebar-nav heading" role="navigation"> <span class="sr-only">Navigation:</span><ul>
<li> <a id="_navigation" href="/blogs/" class="sidebar-nav-item active"> Blog </a>
</li>
<li> <a href="/paperlists/" class="sidebar-nav-item"> PaperLists </a>
</li>
<li> <a href="/projects/" class="sidebar-nav-item"> Projects </a>
</li>
<li> <a href="/Resume/" class="sidebar-nav-item"> Resume </a>
</li>
<li> <a href="/about/" class="sidebar-nav-item"> About ME </a>
</li>
</ul></nav><div class="sidebar-social"> <span class="sr-only">Social:</span><ul></ul>
</div>
</div></header></hy-drawer><hr class="sr-only" hidden> </hy-push-state> <!--[if gt IE 10]><!----> <script nomodule>!function(){var e=document.createElement("script");if(!("noModule"in e)&&"onbeforeload"in e){var t=!1;document.addEventListener("beforeload",function(n){if(n.target===e)t=!0;else if(!n.target.hasAttribute("nomodule")||!t)return;n.preventDefault()},!0),e.type="module",e.src=".",document.head.appendChild(e),e.remove()}}(); </script> <script type="module" src="/assets/js/hydejack-8.5.2.js"></script> <script nomodule src="/assets/js/hydejack-legacy-8.5.2.js" defer></script> <!--<![endif]--><h2 class="sr-only" hidden>Templates (for web app):</h2><template id="_animation-template" hidden><div class="animation-main fixed-top"><div class="content"><div class="page"></div></div></div></template> <template id="_loading-template" hidden><div class="loading nav-btn fr"> <span class="sr-only">Loading…</span> <span class="icon-cog"></span>
</div></template> <template id="_error-template" hidden><div class="page">
<h1 class="page-title">Error</h1>
<p class="lead"> Sorry, an error occurred while loading <a class="this-link" href=""></a>.</p>
</div></template> <template id="_forward-template" hidden> <button id="_forward" class="forward nav-btn no-hover fl"> <span class="sr-only">Forward</span> <span class="icon-arrow-right2"></span> </button> </template> <template id="_back-template" hidden> <button id="_back" class="back nav-btn no-hover fl"> <span class="sr-only">Back</span> <span class="icon-arrow-left2"></span> </button> </template> <template id="_permalink-template" hidden> <a href="#" class="permalink"> <span class="sr-only">Permalink</span> <span class="icon-link"></span> </a> </template> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-156337007-1', 'auto'); ga('send', 'pageview'); </script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-156337007-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-156337007-1'); </script> <script data-ad-client="ca-pub-8231481254980115" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><div id="disqus_thread"></div><script> var disqus_config = function () { this.page.url = "https://xinshaoamoswang.github.io/blogs/2019-10-01-papers-summary-noise/"; this.page.identifier = "/blogs/papers-summary-noise"; }; (function() { var d = document, s = d.createElement('script'); s.src = 'https://xinshaowang.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript> <script id="dsq-count-scr" src="//xinshaowang.disqus.com/count.js" async></script> <script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>