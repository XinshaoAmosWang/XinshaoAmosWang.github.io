<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v8.5.2 <https://hydejack.com/>
--><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><title>Foundations of Deep Learning, Machine Learning | Xinshao Wang</title><meta name="generator" content="Jekyll v3.8.6" /><meta property="og:title" content="Foundations of Deep Learning, Machine Learning" /><meta name="author" content="Xinshao Wang" /><meta property="og:locale" content="en" /><meta name="description" content="“Welcome to my personal website”. 3rd Year PhD Student, will graduate in Sep 2020." /><meta property="og:description" content="“Welcome to my personal website”. 3rd Year PhD Student, will graduate in Sep 2020." /><link rel="canonical" href="https://xinshaowang.com/blogs/2019-12-12-papers-summary-reweighting/" /><meta property="og:url" content="https://xinshaowang.com/blogs/2019-12-12-papers-summary-reweighting/" /><meta property="og:site_name" content="Xinshao Wang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-12-12T00:00:00+00:00" /> <script type="application/ld+json"> {"description":"“Welcome to my personal website”. 3rd Year PhD Student, will graduate in Sep 2020.","author":{"@type":"Person","name":"Xinshao Wang"},"@type":"BlogPosting","url":"https://xinshaowang.com/blogs/2019-12-12-papers-summary-reweighting/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://xinshaowang.com/assets/icons/android-chrome-192x192.png"},"name":"Xinshao Wang"},"headline":"Foundations of Deep Learning, Machine Learning","dateModified":"2019-12-12T00:00:00+00:00","datePublished":"2019-12-12T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://xinshaowang.com/blogs/2019-12-12-papers-summary-reweighting/"},"@context":"https://schema.org"}</script><meta name="keywords" content="Xinshao Wang; Machine Learning,Computer Vision,Robust Learning,Deep Metric Learning,Image Recognition,Video Recognition,Person ReID"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Xinshao Wang"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="application-name" content="Xinshao Wang"><meta name="msapplication-config" content="/assets/ieconfig.xml"><meta name="theme-color" content="rgb(25,55,71)"><meta name="generator" content="Hydejack v8.5.2" /><link type="application/atom+xml" rel="alternate" href="https://xinshaowang.com/feed.xml" title="Xinshao Wang" /><link rel="alternate" href="https://xinshaowang.com/blogs/2019-12-12-papers-summary-reweighting/" hreflang="en"><link rel="shortcut icon" href="/assets/icons/icon.png"><link rel="apple-touch-icon" href="/assets/icons/icon.png"><link rel="manifest" href="/assets/manifest.json"><link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="dns-prefetch" href="/" id="_baseURL"><link rel="dns-prefetch" href="/sw.js" id="_hrefSW"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.js" id="_hrefKatexJS"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.css" id="_hrefKatexCSS"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/contrib/copy-tex.min.js" id="_hrefKatexCopyJS"><link rel="dns-prefetch" href="/assets/bower_components/katex/dist/contrib/copy-tex.min.css" id="_hrefKatexCopyCSS"><link rel="dns-prefetch" href="/assets/img/swipe.svg" id="_hrefSwipeSVG"> <script> !function(e,t){"use strict";function n(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}e.loadJS=function(e,o){var r=t.createElement("script");r.src=e,o&&n(r,"load",o,{once:!0});var a=t.scripts[0];return a.parentNode.insertBefore(r,a),r},e._loaded=!1,e.loadJSDeferred=function(o,r){function a(){e._loaded=!0,r&&n(c,"load",r,{once:!0});var o=t.scripts[0];o.parentNode.insertBefore(c,o)}var c=t.createElement("script");return c.src=o,e._loaded?a():n(e,"load",a,{once:!0}),c},e.setRel=e.setRelStylesheet=function(e){function o(){this.rel="stylesheet"}n(t.getElementById(e),"load",o,{once:!0})}}(window,document); ; !function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this); ; !function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this); ; !function(w, d) { w._noPushState = false; w._noDrawer = false; }(window, document); </script> <!--[if gt IE 8]><!----><style> body{--code-font-family: Menlo,Monaco,Consolas,monospace;--font-weight: 400;--font-weight-bold: 700;--font-weight-heading: 400;--text-muted: #888;--gray-bg: rgba(0,0,0,0.025);--gray-text: #666;--menu-text: #bbb;--body-color: #333;--body-bg: #fff;--border-color: #ebebeb}.clearfix,.sidebar-social::after{content:"";display:table;clear:both}.color-transition,body,p,hr,.hr,table:not(.highlight) td,table:not(.highlight) th,.message{transition:background-color 1s ease, border-color 1s ease}.no-color-transition{transition:none !important}*{box-sizing:border-box}html,body{margin:0;padding:0}html{font-size:16px;line-height:1.75}body{color:var(--body-color);background-color:var(--body-bg);font-weight:var(--font-weight);overflow-y:scroll}a{text-decoration:none}.lead{margin-left:-1rem;margin-right:-1rem}.content img,.img,.content video,.video{max-width:100%}.content img.lead,.img.lead,.content video.lead,.video.lead{max-width:calc(100% + 2rem);width:calc(100% + 2rem)}h1,h2,h3,h4,h5,h6,.h1,.h2,.h3,.h4,.h5,.h6{font-weight:var(--font-weight-heading);margin:5rem 0 1rem}h1,.h1{font-size:2rem;line-height:1.3}h2,.h2{font-size:1.5rem;line-height:1.4}h3,.h3{font-size:1.17em;line-height:1.5}h4,h5,h6,.h4,.h5,.h6{font-size:1rem;margin-bottom:0.5rem}p{margin-top:0;margin-bottom:1rem}p.lead{font-size:1.2em;margin-top:1.5rem;margin-bottom:1.5rem;padding:0 1rem}ul,ol,dl{margin-top:0;margin-bottom:1rem}ul,ol{padding-left:1.25rem}hr{position:relative;margin:3rem 0;border:0;border-top:1px solid var(--border-color)}.hr{border-bottom:1px solid var(--border-color);padding-bottom:1rem;margin-bottom:2rem}table:not(.highlight){border-collapse:collapse;margin-bottom:2rem;margin-left:-1rem}table:not(.highlight) td,table:not(.highlight) th{padding:.25rem .5rem;border:1px solid var(--border-color)}table:not(.highlight) td:first-child,table:not(.highlight) th:first-child{padding-left:1rem}table:not(.highlight) td:last-child,table:not(.highlight) th:last-child{padding-right:1rem}.page{margin-bottom:3em}.page li+li{margin-top:.25rem}.page>header{margin-bottom:2rem}.page-title,.post-title{margin-top:0}.post-date{display:block;margin-top:-0.5rem;margin-bottom:1rem;color:var(--text-muted)}.related-posts{padding-left:0;list-style:none;margin-bottom:2rem}.related-posts>li,.related-posts>li+li{margin-top:1rem}.message{margin-bottom:1rem;padding:1rem;color:var(--gray-text);background-color:var(--gray-bg);margin-left:-1rem;margin-right:-1rem}@media screen{body::before{content:'';width:.5rem;background:var(--border-color);position:fixed;left:0;top:0;bottom:0}}@media screen and (min-width: 64em){body::before{width:21rem}}@media screen and (min-width: 1666px){body::before{width:calc(50% - 28rem)}}@media screen and (min-width: 42em){html{font-size:17px}}@media screen and (min-width: 124em){html{font-size:18px}}.fade-in{animation-duration:500ms;animation-timing-function:ease;animation-name:fade-in;animation-fill-mode:forwards}@keyframes fade-in{from{transform:translateY(-3rem);opacity:0}50%{transform:translateY(-3rem);opacity:0}to{transform:translateY(0);opacity:1}}.fl{float:left}.fr{float:right}.mb4{margin-bottom:4rem}.mb6{margin-bottom:6rem}.mt0{margin-top:0}.mt2{margin-top:2rem}.mt3{margin-top:3rem}.mt4{margin-top:4rem}.pb0{padding-bottom:0}.sixteen-nine{position:relative}.sixteen-nine::before{display:block;content:"";width:100%;padding-top:56.25%}.sixteen-nine>*{position:absolute;top:0;left:0;right:0;bottom:0}.sr-only{display:none}.border{border:1px solid var(--border-color)}hy-push-state a,.a{position:relative;padding-bottom:.15rem;border-bottom:1px solid}hy-push-state a.no-hover,.a.no-hover{border-bottom:none;padding-bottom:0}.content .img{overflow:hidden}.content .img img{margin:0;width:100%;height:100%;background-color:var(--gray-bg)}hy-drawer{width:100%;position:relative;overflow:hidden}@media screen and (min-width: 64em){hy-drawer{position:fixed;width:21rem;top:0;left:0;bottom:0;margin-left:0}hy-drawer.cover{position:relative;width:100%}}@media screen and (min-width: 1666px){hy-drawer{width:calc(50% - 28rem)}}.sidebar{position:relative;display:flex;justify-content:center;align-items:center;color:rgba(255,255,255,0.75);text-align:center;z-index:2;min-height:100vh}.sidebar a{color:#fff;border-bottom-color:rgba(255,255,255,0.2)}.sidebar-bg{position:absolute;top:0;left:calc(50% - 50vw);width:100vw;height:100%;background:#202020 center / cover}.sidebar-bg::after{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background:rgba(0,0,0,0.05)}.sidebar-bg.sidebar-overlay::after{background:linear-gradient(to bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 50%, rgba(32,32,32,0) 100%)}.sidebar-sticky{position:relative;z-index:3;max-width:21rem;padding:1.5rem;contain:content}.sidebar-about .avatar{margin-bottom:1.5rem}.sidebar-about>h2{margin-top:0}.sidebar-nav>ul{list-style:none;padding-left:0}a.sidebar-nav-item{display:inline-block;font-weight:var(--font-weight-heading);line-height:1.75;padding:.25rem;border-bottom:1px solid rgba(255,255,255,0.2)}.sidebar-social>ul{display:inline-block;list-style:none;padding-left:0;margin-bottom:0}.sidebar-social>ul>li{float:left}.sidebar-social>ul>li>a{display:inline-block;text-align:center;font-size:1.4rem;width:3rem;height:4rem;padding:.5rem 0;line-height:3rem}.sidebar-social>ul li+li{margin-top:0}.fixed-common,.fixed-top,.fixed-bottom{position:fixed;left:0;width:100%;z-index:2}.fixed-top{top:0}.fixed-bottom{bottom:0}.navbar>.content{padding-top:0;padding-bottom:0;min-height:0;color:var(--menu-text)}.nav-btn-bar{margin:0 -1rem 0 -.875rem}.nav-btn{background:none;border:none;padding:1.75rem .875rem;color:var(--menu-text) !important;cursor:pointer}.animation-main{opacity:0;pointer-events:none}.content{position:relative;margin-left:auto;margin-right:auto;padding:6rem 1rem 12rem}@media screen{.content{padding-left:1.5rem;max-width:38rem;min-height:100vh}}@media screen and (min-width: 54em){.content{max-width:42rem}}@media screen and (min-width: 64em){.content{padding-left:1rem;margin-left:24rem;margin-right:3rem}}@media screen and (min-width: 88em){.content{margin-left:25rem;margin-right:4rem;max-width:48rem}}@media screen and (min-width: 1666px){.content{margin:auto}}.avatar{width:6.5rem;height:6.5rem;border-radius:100%;overflow:hidden}@media screen and (min-width: 88em){.avatar{width:7rem;height:7rem}}.content .avatar{float:right;margin-left:.5rem}html{font-family:Noto Sans,Helvetica,Arial,sans-serif}h1,h2,h3,h4,h5,h6,.h1,.h2,.h3,.h4,.h5,.h6,.heading{font-family:Roboto Slab,Helvetica,Arial,sans-serif}</style><link rel="preload" as="style" href="/assets/css/hydejack-8.5.2.css" id="_stylePreload"><link rel="preload" as="style" href="/assets/icomoon/style.css" id="_iconsPreload"><link rel="preload" as="style" href="https://fonts.googleapis.com/css?family=Roboto+Slab:400|Noto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload"> <script>setRel('_stylePreload');setRel('_iconsPreload');/**/setRel('_fontsPreload');/**/</script> <noscript><link rel="stylesheet" href="/assets/css/hydejack-8.5.2.css"><link rel="stylesheet" href="/assets/icomoon/style.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:400|Noto+Sans:400,400i,700,700i&display=swap"> </noscript><style id="_pageStyle"> .content a:not(.btn){color:#4fb1ba;border-color:rgba(79,177,186,0.2)}.content a:not(.btn):hover{border-color:#4fb1ba}:focus{outline-color:#4fb1ba !important}.btn-primary{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:focus,.btn-primary.focus,.form-control:focus,.form-control.focus{box-shadow:0 0 0 3px rgba(79,177,186,0.5)}.btn-primary:hover,.btn-primary.hover{color:#fff;background-color:#409ba3;border-color:#409ba3}.btn-primary:disabled,.btn-primary.disabled{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:active,.btn-primary.active{color:#fff;background-color:#409ba3;border-color:#409ba3}::selection{color:#fff;background:#4fb1ba}::-moz-selection{color:#fff;background:#4fb1ba}</style><!--<![endif]--><body class="no-color-transition"><div id="_navbar" class="navbar fixed-top"><div class="content"><div class="nav-btn-bar"> <span class="sr-only">Jump to:</span> <a id="_menu" class="nav-btn no-hover fl" href="#_navigation"> <span class="sr-only">Navigation</span> <span class="icon-menu"></span> </a>
</div></div></div><hr class="sr-only" hidden> <hy-push-state replace-ids="_main" link-selector="a[href]:not([href*='/assets/']):not(.external):not(.no-push-state)" duration="250" script-selector="script:not([type^='math/tex'])" prefetch><main id="_main" class="content fade-in layout-post" role="main" data-color="rgb(79,177,186)" data-theme-color="rgb(25,55,71)" data-image="/assets/img/sidebar-bg.jpg" data-overlay><article id="post-blogs-papers-summary-reweighting" class="page post mb6" role="article"><header><h1 class="post-title"> Foundations of Deep Learning, Machine Learning</h1>
<p class="post-date heading"> <time datetime="2019-12-12T00:00:00+00:00">12 Dec 2019</time> in <a href="/blogs/" class="flip-title">Blogs</a></p>
<div class="hr pb0"></div></header><p class="message"><img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> means being highly related to my personal research interest.</p>
<h2 id="iccv-2019-robustness">ICCV 2019: Robustness</h2>
<ul class="message">
<li><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Gowal_Scalable_Verified_Training_for_Provably_Robust_Image_Classification_ICCV_2019_paper.pdf">Scalable Verified Training for Provably Robust Image Classification</a></li>
<li><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Improving_Adversarial_Robustness_via_Guided_Complement_Entropy_ICCV_2019_paper.pdf">Improving Adversarial Robustness via Guided Complement Entropy</a></li>
<li><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Bilateral_Adversarial_Training_Towards_Fast_Training_of_More_Robust_Models_ICCV_2019_paper.pdf">Bilateral Adversarial Training: Towards Fast Training of More Robust Models Against Adversarial Attacks</a></li>
<li><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Peterson_Human_Uncertainty_Makes_Classification_More_Robust_ICCV_2019_paper.pdf">Human uncertainty makes classification more robust</a></li>
<li><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Yamaguchi_Subspace_Structure-Aware_Spectral_Clustering_for_Robust_Subspace_Clustering_ICCV_2019_paper.pdf">Subspace Structure-aware Spectral Clustering for Robust Subspace Clustering</a></li>
</ul>
<h2 id="1-neurips-2019-learning-data-manipulation-for-augmentation-and-weighting">
<img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> <a href="https://papers.nips.cc/paper/9706-learning-data-manipulation-for-augmentation-and-weighting.pdf">NeurIPS 2019-Learning Data Manipulation for Augmentation and Weighting</a>
</h2>
<ul class="message">
<li>Our approach builds upon a recent connection of supervised learning and reinforcement learning (RL), and adapts an off-the-shelf reward learning algorithm from RL for joint data manipulation learning and model training. Different parameterization of the “data reward” function instantiates different manipulation schemes.</li>
<li>We showcase data augmentation that learns a text transformation network, and data weighting that dynamically adapts the data sample importance. Experiments show the resulting algorithms significantly improve the image and text classification performance in low data regime and class-imbalance problems.</li>
</ul>
<h2 id="1-iclr-2019-critical-learning-periods-in-deep-networks">
<img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> <a href="https://openreview.net/forum?id=BkeStsCcKQ">ICLR 2019-Critical Learning Periods in Deep Networks</a>
</h2>
<ul class="message">
<li>Counterintuitively, information rises rapidly in the early phases of training, and then decreases, preventing redistribution of information resources in a phenomenon we refer to as a loss of “Information Plasticity”</li>
<li>Our analysis suggests that the first few epochs are critical for the creation of strong connections that are optimal relative to the input data distribution. Once such strong connections are created, they do not appear to change during additional training.</li>
<li>The initial learning transient, under-scrutinized compared to asymptotic behavior, plays a key role in determining the outcome of the training process.</li>
<li>The early transient is critical in determining the final solution of the optimization associated with training an artificial neural network. In particular, the effects of sensory deficits during a critical period cannot be overcome, no matter how much additional training is performed.</li>
<li>Our experiments show that, rather than helpful, pre-training can be detrimental, even if the tasks are similar (e.g., same labels, slightly blurred images).</li>
</ul>
<h2 id="1-neurips-2019-time-matters-in-regularizing-deep-networks-weight-decay-and-data-augmentation-affect-early-learning-dynamics-matter-little-near-convergence">
<img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> <a href="https://papers.nips.cc/paper/9252-time-matters-in-regularizing-deep-networks-weight-decay-and-data-augmentation-affect-early-learning-dynamics-matter-little-near-convergence.pdf">NeurIPS 2019-Time Matters in Regularizing Deep Networks: Weight Decay and Data Augmentation Affect Early Learning Dynamics, Matter Little Near Convergence</a>
</h2>
<ul class="message">
<li>Regularization is typically understood as improving generalization by altering the landscape of local extrema to which the model eventually converges. Deep neural networks (DNNs), however, challenge this view: We show that removing regularization after an initial transient period has little effect on generalization, even if the final loss landscape is the same as if there had been no regularization.</li>
<li>In some cases, generalization even improves after interrupting regularization.</li>
<li>Conversely, if regularization is applied only after the initial transient, it has no effect on the final solution, whose generalization gap is as bad as if regularization never happened.</li>
<li>What matters for training deep networks is not just whether or how, but when to regularize.</li>
<li>The phenomena we observe are manifest in different datasets (CIFAR-10, CIFAR-100, SVHN, ImageNet), different architectures (ResNet-18, All-CNN), different regularization methods (weight decay, data augmentation, mixup), different learning rate schedules (exponential, piece-wise constant). They collectively suggest that there is a “critical period” for regularizing deep networks that is decisive of the final performance. More analysis should, therefore, focus on the transient rather than asymptotic behavior of learning.</li>
<li>
<strong>Imposing regularization all along, however, causes over-smoothing</strong>, whereas the ground-truth disparity field is typically discontinuous. So, <strong>regularization is introduced initially and then removed to capture fine details.</strong>
</li>
</ul>
<h2 id="neurips-2019-inherent-weight-normalization-in-stochastic-neural-networks"><a href="https://papers.nips.cc/paper/8591-inherent-weight-normalization-in-stochastic-neural-networks">NeurIPS 2019-Inherent Weight Normalization in Stochastic Neural Networks</a></h2>
<p class="message"><hy-img root-margin="512px" src="/imgs/Inherent_weight_normalisation.png" alt="Full-width image" class="lead" data-width="200" data-height="100">  <noscript><img data-ignore src="/imgs/Inherent_weight_normalisation.png" alt="Full-width image" class="lead" data-width="200" data-height="100"></noscript>  <span slot="loading" class="loading"><span class="icon-cog"></span></span></hy-img></p>
<h2 id="neurips-2019-weight-agnostic-neural-networks"><a href="https://papers.nips.cc/paper/8777-weight-agnostic-neural-networks.pdf">NeurIPS 2019-Weight Agnostic Neural Networks</a></h2>
<p class="message">Not all neural network architectures are created equal, some perform much better than others for certain tasks. But how important are the weight parameters of a neural network compared to its architecture? In this work, we question to what extent neural network architectures alone, without learning any weight parameters, can encode solutions for a given task. We propose a search method for neural network architectures that can already perform a task without any explicit weight training. To evaluate these networks, we populate the connections with a single shared weight parameter sampled from a uniform random distribution, and measure the expected performance. We demonstrate that our method can find minimal neural network architectures that can perform several reinforcement learning tasks without weight training. On a supervised learning domain, we find network architectures that achieve much higher than chance accuracy on MNIST using random weights. Interactive version of this paper at <a href="https://weightagnostic.github.io/">https://weightagnostic.github.io/</a></p></article><hr class="dingbat related"> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], inlineMath: [['$','$'], ['\\(','\\)']], processEscapes: true }, TeX: { equationNumbers: { autoNumber: "AMS" } } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"> </script><div class="navigator"> <span style="float:left"><a href="/projects/2019-10-10-person-reidentification/">« Person Re-identification</a> · <a href="https://xinshaoamoswang.github.io/projects/2019-10-10-person-reidentification/#disqus_thread"></a> </span> <span style="float:right"><a href="/paperlists/2019-12-29-CVPR/">CVPR-2019 »</a> · <a href="https://xinshaoamoswang.github.io/paperlists/2019-12-29-CVPR/#disqus_thread"></a> </span>
</div>
<footer role="contentinfo"><hr>
<p><small class="copyright">© 2019. All rights reserved. </small></p>
<p><small>Welcome to Xinshao Wang's Personal Website</small></p>
<hr class="sr-only"></footer></main><hy-drawer class="" align="left" threshold="10" touch-events prevent-default><header id="_sidebar" class="sidebar" role="banner"><div class="sidebar-bg sidebar-overlay" style="background-color:rgb(25,55,71);background-image:url(/assets/img/sidebar-bg.jpg)"></div>
<div class="sidebar-sticky">
<div class="sidebar-about"> <a class="no-hover" href="/" tabindex="-1"> <img src="/assets/icons/android-chrome-192x192.png" class="avatar" alt="Xinshao Wang" data-ignore> </a><h2 class="h1"><a href="/">Xinshao Wang</a></h2>
<p class="fine"> Machine Learning (Deep Metric Learning, Robust Learning under Arbitrary Anomalies). Computer Vision (Image/Video Recognition, Person ReID).</p>
</div>
<nav class="sidebar-nav heading" role="navigation"> <span class="sr-only">Navigation:</span><ul>
<li> <a id="_navigation" href="/blogs/" class="sidebar-nav-item active"> Blog </a>
</li>
<li> <a href="/paperlists/" class="sidebar-nav-item"> PaperLists </a>
</li>
<li> <a href="/projects/" class="sidebar-nav-item"> Projects </a>
</li>
<li> <a href="/Resume/" class="sidebar-nav-item"> Resume </a>
</li>
<li> <a href="/about/" class="sidebar-nav-item"> About ME </a>
</li>
</ul></nav><div class="sidebar-social"> <span class="sr-only">Social:</span><ul></ul>
</div>
</div></header></hy-drawer><hr class="sr-only" hidden> </hy-push-state> <!--[if gt IE 10]><!----> <script nomodule>!function(){var e=document.createElement("script");if(!("noModule"in e)&&"onbeforeload"in e){var t=!1;document.addEventListener("beforeload",function(n){if(n.target===e)t=!0;else if(!n.target.hasAttribute("nomodule")||!t)return;n.preventDefault()},!0),e.type="module",e.src=".",document.head.appendChild(e),e.remove()}}(); </script> <script type="module" src="/assets/js/hydejack-8.5.2.js"></script> <script nomodule src="/assets/js/hydejack-legacy-8.5.2.js" defer></script> <!--<![endif]--><h2 class="sr-only" hidden>Templates (for web app):</h2><template id="_animation-template" hidden><div class="animation-main fixed-top"><div class="content"><div class="page"></div></div></div></template> <template id="_loading-template" hidden><div class="loading nav-btn fr"> <span class="sr-only">Loading…</span> <span class="icon-cog"></span>
</div></template> <template id="_error-template" hidden><div class="page">
<h1 class="page-title">Error</h1>
<p class="lead"> Sorry, an error occurred while loading <a class="this-link" href=""></a>.</p>
</div></template> <template id="_forward-template" hidden> <button id="_forward" class="forward nav-btn no-hover fl"> <span class="sr-only">Forward</span> <span class="icon-arrow-right2"></span> </button> </template> <template id="_back-template" hidden> <button id="_back" class="back nav-btn no-hover fl"> <span class="sr-only">Back</span> <span class="icon-arrow-left2"></span> </button> </template> <template id="_permalink-template" hidden> <a href="#" class="permalink"> <span class="sr-only">Permalink</span> <span class="icon-link"></span> </a> </template> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-156337007-1', 'auto'); ga('send', 'pageview'); </script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-156337007-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-156337007-1'); </script> <script data-ad-client="ca-pub-8231481254980115" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><div id="disqus_thread"></div><script> var disqus_config = function () { this.page.url = "https://xinshaoamoswang.github.io/blogs/2019-12-12-papers-summary-reweighting/"; this.page.identifier = "/blogs/papers-summary-reweighting"; }; (function() { var d = document, s = d.createElement('script'); s.src = 'https://xinshaowang.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript> <script id="dsq-count-scr" src="//xinshaowang.disqus.com/count.js" async></script> <script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>