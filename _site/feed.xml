<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2019-10-07T18:31:42+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Xinshao Wang</title><subtitle>&quot;Welcome to my personal website&quot;. **3rd Year PhD Student**, will graduate in Sep 2020.
</subtitle><author><name>Xinshao Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><entry><title type="html">An Extremely Simple and Principled Solution for Robust Learning under Arbitrary Anomalies</title><link href="http://localhost:4000/blogs/2019-10-01-Research-GR/" rel="alternate" type="text/html" title="An Extremely Simple and Principled Solution for Robust Learning under Arbitrary Anomalies" /><published>2019-10-01T00:00:00+01:00</published><updated>2019-10-01T00:00:00+01:00</updated><id>http://localhost:4000/blogs/Research-GR</id><content type="html" xml:base="http://localhost:4000/blogs/2019-10-01-Research-GR/">&lt;p&gt;General applicability: Label noise (semantic noise), outliers, heavy perceptual data noise, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;It is reasonable to assume that there is semantic noise in large-scale training datasets&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Class labels may be missing.&lt;/li&gt;
  &lt;li&gt;The labelling process may be subjective.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Label noise is one of the most explicit cases where some observations and their labels are not matched in the training data. In this case, it is quite crucial to make your models learn meaningful patterns instead of errors.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Main contribution:&lt;/strong&gt; Intuitively and principally, we claim that two basic factors, what examples
get higher weights (emphasis focus) and how large variance over examples’ weights (emphasis
spread), should be babysit simultaneously when it comes to sample differentiation and reweighting.
Unfortunately, these two intuitive and indispensable factors are not studied together in the literature.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What training examples should be focused and how much more should they be emphasised when training DNNs under label noise?&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;When noise rate is higher, we can improve a model’s robustness by focusing on relatively less difficult examples.&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://www.researchgate.net/publication/333418661_Emphasis_Regularisation_by_Gradient_Rescaling_for_Training_Deep_Neural_Networks_with_Noisy_Labels/comments&quot;&gt;More comments and comparison with related work&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://drive.google.com/file/d/1fU3N_u-_puOwEbupK6aOENerP2S45tZX/view?usp=sharing&quot;&gt;Paper reading about outlier detection and robust inference&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;effective-qualitative-and-quantitative-results&quot;&gt;Effective (Qualitative and Quantitative Results)&lt;/h2&gt;

&lt;p&gt;Please see &lt;a href=&quot;https://arxiv.org/pdf/1905.11233.pdf&quot;&gt;our paper&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Outperform existing work on synthetic label noise;&lt;/li&gt;
  &lt;li&gt;Outperform existing work on unknown real-world noise.&lt;/li&gt;
&lt;/ul&gt;

&lt;p float=&quot;left&quot;&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Figure1.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Table1.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Figure2.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Table4.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Table5.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Table6.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Table7.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/img/blog/figs/Table9.png&quot; width=&quot;800&quot; /&gt;
&lt;/p&gt;

&lt;h2 id=&quot;extremely-simple&quot;&gt;Extremely Simple&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Without advanced training strategies&lt;/strong&gt;: e.g.,&lt;/p&gt;

&lt;p&gt;a. Iterative retraining on gradual data correction&lt;/p&gt;

&lt;p&gt;b. Training based on carefully-designed curriculums&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Without using extra networks&lt;/strong&gt;: e.g.,&lt;/p&gt;

&lt;p&gt;a. Decoupling” when to update” from” how to update”&lt;/p&gt;

&lt;p&gt;b. Co-teaching: Robust training of deep neural networks with extremely noisy labels&lt;/p&gt;

&lt;p&gt;c. Mentornet: Learning datadriven curriculum for very deep neural networks on corrupted labels&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Without using extra validation sets for model optimisation&lt;/strong&gt;: e.g.,&lt;/p&gt;

&lt;p&gt;a.  Learning to reweight examples for
robust deep learning&lt;/p&gt;

&lt;p&gt;b. Mentornet: Learning datadriven curriculum for very deep neural networks on corrupted labels&lt;/p&gt;

&lt;p&gt;c. Toward robustness against label noise in training deep discriminative neural networks&lt;/p&gt;

&lt;p&gt;d. Learning
from noisy large-scale datasets with minimal supervision.&lt;/p&gt;

&lt;p&gt;e. Learning from
noisy labels with distillation.&lt;/p&gt;

&lt;p&gt;f. Cleannet: Transfer learning for
scalable image classifier training with label noise&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Without data pruning&lt;/strong&gt;: e.g.,&lt;/p&gt;

&lt;p&gt;a. Generalized cross entropy loss for training deep neural networks
with noisy labels. &lt;br /&gt;
  …&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Without relabelling&lt;/strong&gt;: e.g.,&lt;/p&gt;

&lt;p&gt;a. A semi-supervised two-stage approach
to learning from noisy labels&lt;/p&gt;

&lt;p&gt;b. Joint optimization framework for learning with noisy labels&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;h2 id=&quot;citation&quot;&gt;Citation&lt;/h2&gt;
&lt;p&gt;Please kindly cite us if you find our work useful and inspiring.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@article&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;wang2019emphasis,
  &lt;span class=&quot;nv&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;Emphasis Regularisation by Gradient Rescaling &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;Training Deep Neural Networks Robustly&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
  &lt;span class=&quot;nv&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;Wang, Xinshao and Hua, Yang and Kodirov, Elyor and Robertson, Neil&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
  &lt;span class=&quot;nv&quot;&gt;journal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;arXiv preprint arXiv:1905.11233&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
  &lt;span class=&quot;nv&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;2019&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Eran Malach and Shai Shalev-Shwartz. Decoupling” when to update” from” how to update”. In
NIPS, 2017.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In
NIPS, 2018&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning datadriven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In ICML, 2018.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Arash Vahdat. Toward robustness against label noise in training deep discriminative neural networks.
In NIPS, 2017.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and Serge Belongie. Learning
from noisy large-scale datasets with minimal supervision. In CVPR, 2017.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo, and Li-Jia Li. Learning from
noisy labels with distillation. In ICCV, 2017.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kuang-Huei Lee, Xiaodong He, Lei Zhang, and Linjun Yang. Cleannet: Transfer learning for
scalable image classifier training with label noise. In CVPR, 2018.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Zhilu Zhang and Mert R Sabuncu. Generalized cross entropy loss for training deep neural networks
with noisy labels. In NIPS, 2018.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Yifan Ding, Liqiang Wang, Deliang Fan, and Boqing Gong. A semi-supervised two-stage approach
to learning from noisy labels. In WACV, 2018.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hwanjun Song, Minseok Kim, and Jae-Gil Lee. Selfie: Refurbishing unclean samples for robust
deep learning. In ICML, 2019.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization framework for learning with noisy labels. In CVPR, 2018.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">General applicability: Label noise (semantic noise), outliers, heavy perceptual data noise, etc.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/GR/Figure1.png" /></entry><entry><title type="html">Paper Summary on Distance Metric, Representation Learning</title><link href="http://localhost:4000/blogs/2019-10-01-papers-summary-metric/" rel="alternate" type="text/html" title="Paper Summary on Distance Metric, Representation Learning" /><published>2019-10-01T00:00:00+01:00</published><updated>2019-10-01T00:00:00+01:00</updated><id>http://localhost:4000/blogs/papers-summary-metric</id><content type="html" xml:base="http://localhost:4000/blogs/2019-10-01-papers-summary-metric/">&lt;p class=&quot;message&quot;&gt;Paper Notes on Distance Metric, Representation Learning &lt;br /&gt;
:+1: means being highly related to my personal research interest.&lt;/p&gt;

&lt;h2 id=&quot;few-shot-learning&quot;&gt;&lt;a href=&quot;/my_docs/few-shot/&quot;&gt;Few-shot Learning&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:&lt;/p&gt;

&lt;h2 id=&quot;large-output-spaces&quot;&gt;&lt;a href=&quot;/my_docs/large-output-spaces/&quot;&gt;Large Output Spaces&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:&lt;/p&gt;

&lt;h2 id=&quot;poincaré-hyperbolic-curvilinear&quot;&gt;&lt;a href=&quot;/my_docs/Poincare-Hyperbolic-Curvilinear/&quot;&gt;Poincaré, Hyperbolic, Curvilinear&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:&lt;/p&gt;

&lt;h2 id=&quot;wasserstein&quot;&gt;&lt;a href=&quot;/my_docs/wasserstein/&quot;&gt;Wasserstein&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:&lt;/p&gt;

&lt;h2 id=&quot;1-cvpr-2019-label-propagation-for-deep-semi-supervised-learning&quot;&gt;:+1: &lt;a href=&quot;http://openaccess.thecvf.com/content_CVPR_2019/papers/Iscen_Label_Propagation_for_Deep_Semi-Supervised_Learning_CVPR_2019_paper.pdf&quot;&gt;CVPR 2019-Label Propagation for Deep Semi-supervised Learning&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: 
Semi-supervised learning is becoming increasingly important because it can combine data carefully labeled by humans with abundant unlabeled data to train deep neural networks. Classic methods on semi-supervised learning that have focused on transductive learning have not been fully exploited in the inductive framework followed by modern deep learning. The same holds for the manifold assumption—that similar examples should get the same prediction. &lt;br /&gt;
In this work, we employ a transductive label propagation method that is based on the &lt;strong&gt;manifold assumption to make predictions&lt;/strong&gt; on the entire dataset and use these predictions to generate pseudo-labels for the unlabeled data and train a deep neural network. At the core of the transductive method lies &lt;strong&gt;a nearest neighbor graph of the dataset that we create based on the embeddings of the same network.&lt;/strong&gt; 
Therefore our learning process &lt;strong&gt;iterates between these two steps.&lt;/strong&gt; We improve performance on several datasets especially in the few labels regime and show that our work is complementary to current state of the art.&lt;/p&gt;

&lt;h2 id=&quot;1-iclr-2019-unsupervised-learning-via-meta-learning&quot;&gt;:+1: &lt;a href=&quot;https://openreview.net/pdf?id=r1My6sR9tX&quot;&gt;ICLR 2019-Unsupervised Learning via Meta-Learning&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: 
A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. &lt;br /&gt;
Many prior unsupervised learning works aim to do so by developing &lt;strong&gt;proxy objectives based on reconstruction, disentanglement, prediction, and other metrics.&lt;/strong&gt; &lt;br /&gt;
Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, &lt;strong&gt;we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks.&lt;/strong&gt; Surprisingly, we find that, &lt;strong&gt;when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings&lt;/strong&gt;, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods.&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-stochastic-shared-embeddings-data-driven-regularization-of-embedding-layers&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1905.10630.pdf&quot;&gt;NeurIPS 2019-Stochastic Shared Embeddings: Data-driven Regularization of Embedding Layers&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: 
In deep neural nets, lower level embedding layers account for a large portion of the total number of parameters.&lt;strong&gt;Tikhonov regularization, graph-based regularization, and hard parameter sharing are approaches that introduce explicit biases into training in a hope to reduce statistical complexity.&lt;/strong&gt; Alternatively, we propose stochastically shared embeddings (SSE), a data-driven approach to regularizing embedding layers, which stochastically transitions between embeddings during stochastic gradient descent (SGD). Because SSE integrates seamlessly with existing SGD algorithms, it can be used with only minor modifications when training large scale neural networks. We develop two versions of SSE: SSE-Graph using knowledge graphs of embeddings; SSE-SE using no prior information. We provide theoretical guarantees for our method and show its empirical effectiveness on 6 distinct tasks, from simple neural networks with one hidden layer in recommender systems, to the transformer and BERT in natural languages. &lt;strong&gt;We find that when used along with widely-used regularization methods such as weight decay and dropout, our proposed SSE can further reduce overfitting, which often leads to more favorable generalization results.&lt;/strong&gt; &lt;br /&gt;
We conducted &lt;strong&gt;experiments for a total of 6 tasks from simple neural networks with one hidden layer in recommender systems, to the transformer and BERT in natural languages.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-metric-learning-for-adversarial-robustness&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1909.00900.pdf&quot;&gt;NeurIPS 2019-Metric Learning for Adversarial Robustness&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: 
Deep networks are well-known to be fragile to adversarial attacks. Using several standard image datasets and established attack mechanisms, we conduct an empirical analysis of deep representations under attack, and find that the &lt;strong&gt;attack causes the internal representation to shift closer to the “false” class. Motivated by this observation, we propose to regularize the representation space under attack with metric learning in order to produce more robust classifiers.&lt;/strong&gt; By carefully sampling examples for metric learning, our learned representation not only &lt;strong&gt;increases robustness, but also can detect previously unseen adversarial samples.&lt;/strong&gt; Quantitative experiments show improvement of robustness accuracy by up to 4% and detection efficiency by up to 6% according to Area Under Curve (AUC) score over baselines.&lt;/p&gt;</content><author><name>Xinshao Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Paper Notes on Distance Metric, Representation Learning :+1: means being highly related to my personal research interest.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/steve-harvey.jpg" /></entry><entry><title type="html">Paper Summary on Noise, Anomalies, Adversaries</title><link href="http://localhost:4000/blogs/2019-10-01-papers-summary-noise/" rel="alternate" type="text/html" title="Paper Summary on Noise, Anomalies, Adversaries" /><published>2019-10-01T00:00:00+01:00</published><updated>2019-10-01T00:00:00+01:00</updated><id>http://localhost:4000/blogs/papers-summary-noise</id><content type="html" xml:base="http://localhost:4000/blogs/2019-10-01-papers-summary-noise/">&lt;p class=&quot;message&quot;&gt;Paper Notes on Noise (Label noise, adversarial examples, anomalies, outliers, etc) &lt;br /&gt;
:+1: means being highly related to my personal research interest.&lt;/p&gt;

&lt;h2 id=&quot;adversarial-examples-reading-list&quot;&gt;&lt;a href=&quot;/my_docs/Adversarial-Examples-Reading-List/&quot;&gt;Adversarial Examples Reading List&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: 
To be done &lt;em&gt;55 papers with key words on Adversarial from NeurIPS 2019&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;icml-2019-improving-adversarial-robustness-via-promoting-ensemble-diversity&quot;&gt;&lt;a href=&quot;http://proceedings.mlr.press/v97/pang19a/pang19a.pdf&quot;&gt;ICML 2019-Improving Adversarial Robustness via Promoting Ensemble Diversity&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: 
Though deep neural networks have achieved significant progress on various tasks, often enhanced by model ensemble, existing high-performance models can be vulnerable to adversarial attacks. &lt;strong&gt;Many efforts have been devoted to enhancing the robustness of individual networks and then constructing a straightforward ensemble, e.g., by directly averaging the outputs, which ignores the interaction among networks.&lt;/strong&gt; This paper presents a new method that &lt;strong&gt;explores the interaction among individual networks to improve robustness for ensemble models.&lt;/strong&gt; Technically, we define a new notion of &lt;strong&gt;ensemble diversity in the adversarial setting&lt;/strong&gt; as the diversity among non-maximal predictions of individual members, and &lt;strong&gt;present an adaptive diversity promoting (ADP) regularizer to encourage the diversity,&lt;/strong&gt; which leads to globally better robustness for the ensemble by making adversarial examples difficult to transfer among individual members. Our method is computationally efficient and compatible with the defense methods acting on individual networks. Empirical results on various datasets verify that our method can improve adversarial robustness while maintaining state-of-the-art accuracy on normal examples.&lt;/p&gt;

&lt;h2 id=&quot;1-neurips-2019-metric-learning-for-adversarial-robustness&quot;&gt;:+1: &lt;a href=&quot;https://arxiv.org/pdf/1909.00900.pdf&quot;&gt;NeurIPS 2019-Metric Learning for Adversarial Robustness&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: 
Deep networks are well-known to be fragile to adversarial attacks. Using several standard image datasets and established attack mechanisms, we conduct an empirical analysis of deep representations under attack, and find that the attack causes the internal representation to shift closer to the “false” class. Motivated by this observation, &lt;strong&gt;we propose to regularize the representation space under attack with metric learning in order to produce more robust classifiers.&lt;/strong&gt; &lt;strong&gt;By carefully sampling examples for metric learning,&lt;/strong&gt; our learned representation not only increases robustness, but also can detect previously unseen adversarial samples. Quantitative experiments show improvement of robustness accuracy by up to 4% and detection efficiency by up to 6% according to Area Under Curve (AUC) score over baselines.&lt;/p&gt;

&lt;h2 id=&quot;1-icml-2019-a-tail-index-analysis-of-stochastic-gradient-noise-in-deep-neural-networks&quot;&gt;:+1: &lt;a href=&quot;http://proceedings.mlr.press/v97/simsekli19a/simsekli19a.pdf&quot;&gt;ICML 2019-A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Stochastic Gradient Noise &lt;br /&gt;
Stochastic gradient descent (SGD) has been widely used in machine learning due to its computational efficiency and favorable generalization properties. Recently, it has been empirically demonstrated that the gradient noise in several deep learning settings admits a non-Gaussian, heavy-tailed behavior. &lt;strong&gt;This suggests that the gradient noise can be modeled by using α-stable distributions, a family of heavy-tailed distributions that appear in the generalized central limit theorem. In this context, SGD can be viewed as a discretization of a stochastic differential equation (SDE) driven by a Lévy motion, and the metastability results for this SDE can then be used for illuminating the behavior of SGD, especially in terms of `preferring wide minima’.&lt;/strong&gt; While this approach brings a new perspective for analyzing SGD, it is limited in the sense that, due to the time discretization, SGD might admit a significantly different behavior than its continuous-time limit. Intuitively, the behaviors of these two systems are expected to be similar to each other only when the discretization step is sufficiently small; however, to the best of our knowledge, &lt;strong&gt;there is no theoretical understanding on how small the step-size should be chosen in order to guarantee that the discretized system inherits the properties of the continuous-time system.&lt;/strong&gt; In this study, we provide formal theoretical analysis where we derive explicit conditions for the step-size such that the metastability behavior of the discrete-time system is similar to its continuous-time limit. We show that the behaviors of the two systems are indeed similar for small step-sizes and we identify how the error depends on the algorithm and problem parameters. We illustrate our results with simulations on a synthetic model and neural networks.&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-first-exit-time-analysis-of-stochastic-gradient-descent-under-heavy-tailed-gradient-noise&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1906.09069.pdf&quot;&gt;NeurIPS 2019-First Exit Time Analysis of Stochastic Gradient Descent Under Heavy-Tailed Gradient Noise&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Stochastic Gradient Noise&lt;/p&gt;

&lt;h2 id=&quot;1--neurips-2019-noise-tolerant-fair-classification&quot;&gt;:+1:  &lt;a href=&quot;https://arxiv.org/abs/1901.10837&quot;&gt;NeurIPS 2019-Noise-tolerant fair classification&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Existing work on the problem operates &lt;strong&gt;under the assumption that the sensitive feature available in one’s training sample is perfectly reliable.&lt;/strong&gt; This assumption may be violated in many real-world cases: for example, respondents to a survey may choose to conceal or obfuscate their group identity out of fear of potential discrimination. This poses the question of whether one can still learn fair classifiers given noisy sensitive features.&lt;/p&gt;

&lt;h2 id=&quot;1--neurips-2019-reducing-noise-in-gan-training-with-variance-reduced-extragradient&quot;&gt;:+1:  &lt;a href=&quot;https://arxiv.org/abs/1904.08598&quot;&gt;NeurIPS 2019-Reducing Noise in GAN Training with Variance Reduced Extragradient&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: We study the effect of the &lt;strong&gt;stochastic gradient noise&lt;/strong&gt; on the training of generative adversarial networks (GANs) and show that it can prevent the convergence of standard game optimization methods, while the batch version converges. We address this issue with a novel &lt;strong&gt;stochastic variance-reduced extragradient (SVRE)&lt;/strong&gt; optimization algorithm that improves upon the best convergence rates proposed in the literature. We observe empirically that SVRE performs similarly to a batch method on MNIST while being computationally cheaper, and that SVRE yields more stable GAN training on standard datasets.&lt;/p&gt;

&lt;h2 id=&quot;1-neurips-2019-combinatorial-inference-against-label-noise&quot;&gt;:+1: &lt;a href=&quot;&quot;&gt;NeurIPS 2019-Combinatorial Inference against Label Noise&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Paper is not available yet.&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-extending-steins-unbiased-risk-estimator-to-train-deep-denoisers-with-correlated-pairs-of-noisy-images&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1902.02452.pdf&quot;&gt;NeurIPS 2019-Extending Stein’s unbiased risk estimator to train deep denoisers with correlated pairs of noisy images&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Recently, Stein’s unbiased risk estimator (SURE) has been applied to &lt;strong&gt;unsupervised training of deep neural network Gaussian denoisers that outperformed classical non-deep learning based denoisers and yielded comparable performance to those trained with ground truth.&lt;/strong&gt; While SURE requires only one noise realization per image for training, it does not take advantage of having multiple noise realizations per image when they are available (e.g., two uncorrelated noise realizations per image for Noise2Noise). Here, we propose an extended SURE (eSURE) to train &lt;strong&gt;deep denoisers with correlated pairs of noise realizations per image&lt;/strong&gt; and applied it to the case with two uncorrelated realizations per image to achieve better performance than SURE based method and comparable results to Noise2Noise. Then, we further investigated &lt;strong&gt;the case with imperfect ground truth (i.e., mild noise in ground truth) that may be obtained considering painstaking, time-consuming, and even expensive processes of collecting ground truth images with multiple noisy images.&lt;/strong&gt; For the case of generating noisy training data by adding synthetic noise to imperfect ground truth to yield correlated pairs of images, our proposed eSURE based training method outperformed conventional SURE based method as well as Noise2Noise.&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-variational-denoising-network-toward-blind-noise-modeling-and-removal&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1908.11314.pdf&quot;&gt;NeurIPS 2019-Variational Denoising Network: Toward Blind Noise Modeling and Removal&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Blind image denoising is an important yet very challenging problem in computer vision due to the complicated acquisition process of real images. In this work we propose a new variational inference method, which integrates both noise estimation and image denoising into a unique Bayesian framework, for blind image denoising. Specifically, an approximate posterior, parameterized by deep neural networks, is presented by taking the intrinsic clean image and noise variances as latent variables conditioned on the input noisy image. This posterior provides explicit parametric forms for all its involved hyper-parameters, and thus can be easily implemented for blind image denoising with automatic noise estimation for the test noisy image. On one hand, as other data-driven deep learning methods, our method, namely variational denoising network (VDN), can perform denoising efficiently due to its explicit form of posterior expression. On the other hand, VDN inherits the advantages of traditional model-driven approaches, especially the good generalization capability of generative models. VDN has good interpretability and can be flexibly utilized to estimate and remove complicated non-i.i.d. noise collected in real scenarios. Comprehensive experiments are performed to substantiate the superiority of our method in blind image denoising. &lt;br /&gt;
&lt;a href=&quot;https://github.com/zsyOAOA/VDNet&quot;&gt;Pytorch Code&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-neural-networks-grown-and-self-organized-by-noise&quot;&gt;&lt;a href=&quot;https://arxiv.org/abs/1906.01039&quot;&gt;NeurIPS 2019-Neural networks grown and self-organized by noise&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Living neural networks emerge through a process of growth and self-organization that begins with a single cell and results in a brain, an organized and functional computational device. Artificial neural networks, however, rely on human-designed, hand-programmed architectures for their remarkable performance. Can we develop artificial computational devices that can grow and self-organize without human intervention? In this paper, we propose a biologically inspired developmental algorithm that can ‘grow’ a functional, layered neural network from a single initial cell. The algorithm organizes inter-layer connections to construct a convolutional pooling layer, a key constituent of convolutional neural networks (CNN’s). Our approach is inspired by the mechanisms employed by the early visual system to wire the retina to the lateral geniculate nucleus (LGN), days before animals open their eyes. The key ingredients for robust self-organization are an emergent spontaneous spatiotemporal activity wave in the first layer and a local learning rule in the second layer that ‘learns’ the underlying activity pattern in the first layer. The algorithm is adaptable to a wide-range of input-layer geometries, robust to malfunctioning units in the first layer, and so can be used to successfully grow and self-organize pooling architectures of different pool-sizes and shapes. The algorithm provides a primitive procedure for constructing layered neural networks through growth and self-organization. Broadly, our work shows that biologically inspired developmental algorithms can be applied to autonomously grow functional ‘brains’ in-silico.&lt;/p&gt;

&lt;h2 id=&quot;1-neurips-2019-l_dmi-a-novel-information-theoretic-loss-function-for-training-deep-nets-robust-to-label-noise&quot;&gt;:+1: &lt;a href=&quot;https://arxiv.org/pdf/1909.03388.pdf&quot;&gt;NeurIPS 2019-L_DMI: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Accurately annotating large scale dataset is notoriously expensive both in time and in money. Although acquiring low-quality-annotated dataset can be much cheaper, it often badly damages the performance of trained models when using such dataset without particular treatment. Various of methods have been proposed for learning with noisy labels. However, &lt;strong&gt;they only handle limited kinds of noise patterns, require auxiliary information (e.g,, the noise transition matrix), or lack theoretical justification.&lt;/strong&gt; In this paper, we propose a novel &lt;strong&gt;information-theoretic loss function,&lt;/strong&gt; LDMI, for training deep neural networks robust to label noise. The core of LDMI is a generalized version of mutual information, termed Determinant based Mutual Information (DMI), which is not only information-monotone but also relatively invariant. \emph{To the best of our knowledge, LDMI is the first loss function that is &lt;strong&gt;provably not sensitive to noise patterns and noise amounts&lt;/strong&gt;, and it can be applied to any existing classification neural networks straightforwardly &lt;strong&gt;without any auxiliary information&lt;/strong&gt;}. In addition to theoretical justification, we also empirically show that using LDMI outperforms all other counterparts in the classification task on &lt;strong&gt;Fashion-MNIST, CIFAR-10, Dogs vs. Cats datasets with a variety of synthesized noise patterns and noise amounts as well as a real-world dataset Clothing1M&lt;/strong&gt;. &lt;br /&gt; 
Codes are available at &lt;a href=&quot;https://github.com/Newbeeer/L_DMI&quot;&gt;https://github.com/Newbeeer/L_DMI&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-are-anchor-points-really-indispensable-in-label-noise-learning&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1906.00189.pdf&quot;&gt;NeurIPS 2019-Are Anchor Points Really Indispensable in Label-Noise Learning?&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: In label-noise learning, \textit{noise transition matrix}, denoting the probabilities that clean labels flip into noisy labels, plays a central role in building \textit{statistically consistent classifiers}. Existing theories have shown that the transition matrix can be learned by exploiting \textit{anchor points} (i.e., data points that belong to a specific class almost surely). However, when there are no anchor points, the transition matrix will be poorly learned, and those current consistent classifiers will significantly degenerate. In this paper, without employing anchor points, we propose a \textit{transition-revision} (T-Revision) method to effectively learn transition matrices, leading to better classifiers. Specifically, to learn a transition matrix, we first initialize it by exploiting data points that are similar to anchor points, having high \textit{noisy class posterior probabilities}. Then, we modify the initialized matrix by adding a \textit{slack variable}, which can be learned and validated together with the classifier by using noisy data. Empirical results on benchmark-simulated and real-world label-noise datasets demonstrate that without using exact anchor points, the proposed method is superior to the state-of-the-art label-noise learning methods.&lt;/p&gt;

&lt;h2 id=&quot;neurips-2019-certified-adversarial-robustness-with-additive-gaussian-noise&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1809.03113.pdf&quot;&gt;NeurIPS 2019-Certified Adversarial Robustness with Additive Gaussian Noise&lt;/a&gt;&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The existence of adversarial data examples has drawn significant attention in the deep-learning community; such data are seemingly minimally perturbed relative to the original data, but lead to very different outputs from a deep-learning algorithm. Although a significant body of work on developing defense models has been developed, most such models are heuristic and are often vulnerable to adaptive attacks. Defensive methods that provide theoretical robustness guarantees have been studied intensively, yet most fail to obtain non-trivial robustness when a large-scale model and data are present. To address these limitations, we introduce a framework that is scalable and provides certified bounds on the norm of the input manipulation for constructing adversarial examples. We establish a connection between robustness against adversarial perturbation and additive random noise, and propose a training strategy that can significantly improve the certified bounds. Our evaluation on MNIST, CIFAR-10 and ImageNet suggests that our method is scalable to complicated models and large data sets, while providing competitive robustness to state-of-the-art provable defense methods.&lt;/p&gt;</content><author><name>Xinshao Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Paper Notes on Noise (Label noise, adversarial examples, anomalies, outliers, etc) :+1: means being highly related to my personal research interest.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/steve-harvey.jpg" /></entry><entry><title type="html">Start 3rd year (the final year of my PhD)</title><link href="http://localhost:4000/projects/2019-10-01-PhD-3rd-start/" rel="alternate" type="text/html" title="Start 3rd year (the final year of my PhD)" /><published>2019-10-01T00:00:00+01:00</published><updated>2019-10-01T00:00:00+01:00</updated><id>http://localhost:4000/projects/PhD-3rd-start</id><content type="html" xml:base="http://localhost:4000/projects/2019-10-01-PhD-3rd-start/">&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This post is outdated and only included for legacy reasons.
See the &lt;a href=&quot;/docs/&quot;&gt;Documentation&lt;/a&gt; for up-to-date instructions.&lt;/p&gt;</content><author><name>XinshaoAmosWang</name></author><summary type="html">NOTE: This post is outdated and only included for legacy reasons. See the Documentation for up-to-date instructions.</summary></entry><entry><title type="html">Example Content III</title><link href="http://localhost:4000/blogs/2019-06-01-example-content-iii/" rel="alternate" type="text/html" title="Example Content III" /><published>2019-06-01T00:00:00+01:00</published><updated>2019-06-01T00:00:00+01:00</updated><id>http://localhost:4000/blogs/example-content-iii</id><content type="html" xml:base="http://localhost:4000/blogs/2019-06-01-example-content-iii/">&lt;p&gt;Hydejack offers a few additional features to markup your markdown.
Don’t worry, these are merely CSS classes added with kramdown’s &lt;code class=&quot;highlighter-rouge&quot;&gt;{:...}&lt;/code&gt; syntax,
so that your content remains compatible with other Jekyll themes.&lt;/p&gt;

&lt;h2 id=&quot;large-tables&quot;&gt;Large Tables&lt;/h2&gt;

&lt;table class=&quot;scroll-table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Default aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Left aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Center aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Right aligned&lt;/th&gt;
      &lt;th&gt;Default aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Left aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Center aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Right aligned&lt;/th&gt;
      &lt;th&gt;Default aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Left aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Center aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Right aligned&lt;/th&gt;
      &lt;th&gt;Default aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Left aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Center aligned&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Right aligned&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;First body part&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Second cell&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Third cell&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;fourth cell&lt;/td&gt;
      &lt;td&gt;First body part&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Second cell&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Third cell&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;fourth cell&lt;/td&gt;
      &lt;td&gt;First body part&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Second cell&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Third cell&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;fourth cell&lt;/td&gt;
      &lt;td&gt;First body part&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Second cell&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Third cell&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;fourth cell&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Second line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;foo&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;strong&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;baz&lt;/td&gt;
      &lt;td&gt;Second line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;foo&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;strong&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;baz&lt;/td&gt;
      &lt;td&gt;Second line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;foo&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;strong&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;baz&lt;/td&gt;
      &lt;td&gt;Second line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;foo&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;strong&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;baz&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Third line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;quux&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;baz&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;bar&lt;/td&gt;
      &lt;td&gt;Third line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;quux&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;baz&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;bar&lt;/td&gt;
      &lt;td&gt;Third line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;quux&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;baz&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;bar&lt;/td&gt;
      &lt;td&gt;Third line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;quux&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;baz&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;bar&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Second body&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Second body&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Second body&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Second body&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2 line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;2 line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;2 line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;2 line&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Footer row&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Footer row&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Footer row&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
      &lt;td&gt;Footer row&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;code-blocks&quot;&gt;Code blocks&lt;/h2&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Example can be run directly in your JavaScript console&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Create a function that takes two arguments and returns the sum of those&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// arguments&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;adder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;return a + b&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Call the function&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;adder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// &amp;gt; 8&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;math&quot;&gt;Math&lt;/h2&gt;
&lt;p&gt;Lorem ipsum &lt;code class=&quot;MathJax_Preview&quot;&gt;f(x) = x^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;f(x) = x^2&lt;/script&gt;.&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
  \phi(x,y) &amp;amp;= \phi \left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j \right) \\[2em]
            &amp;amp;= \sum_{i=1}^n \sum_{j=1}^n x_i y_j \phi(e_i, e_j)            \\[2em]
            &amp;amp;= (x_1, \ldots, x_n)
               \left(\begin{array}{ccc}
                 \phi(e_1, e_1)  &amp;amp; \cdots &amp;amp; \phi(e_1, e_n) \\
                 \vdots          &amp;amp; \ddots &amp;amp; \vdots         \\
                 \phi(e_n, e_1)  &amp;amp; \cdots &amp;amp; \phi(e_n, e_n)
               \end{array}\right)
               \left(\begin{array}{c}
                 y_1    \\
                 \vdots \\
                 y_n
               \end{array}\right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
  \phi(x,y) &amp;= \phi \left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j \right) \\[2em]
            &amp;= \sum_{i=1}^n \sum_{j=1}^n x_i y_j \phi(e_i, e_j)            \\[2em]
            &amp;= (x_1, \ldots, x_n)
               \left(\begin{array}{ccc}
                 \phi(e_1, e_1)  &amp; \cdots &amp; \phi(e_1, e_n) \\
                 \vdots          &amp; \ddots &amp; \vdots         \\
                 \phi(e_n, e_1)  &amp; \cdots &amp; \phi(e_n, e_n)
               \end{array}\right)
               \left(\begin{array}{c}
                 y_1    \\
                 \vdots \\
                 y_n
               \end{array}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;message-boxes&quot;&gt;Message boxes&lt;/h2&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: You can add a message box.&lt;/p&gt;

&lt;h2 id=&quot;large-text&quot;&gt;Large text&lt;/h2&gt;
&lt;p class=&quot;lead&quot;&gt;You can add large text.&lt;/p&gt;

&lt;h2 id=&quot;large-images&quot;&gt;Large images&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://placehold.it/800x100&quot; alt=&quot;Full-width image&quot; class=&quot;lead&quot; data-width=&quot;800&quot; data-height=&quot;100&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;captions-to-images&quot;&gt;Captions to images&lt;/h2&gt;
&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://placehold.it/800x100&quot; alt=&quot;Full-width image&quot; class=&quot;lead&quot; data-width=&quot;800&quot; data-height=&quot;100&quot; /&gt;
A caption to an image.&lt;/p&gt;

&lt;h2 id=&quot;large-quotes&quot;&gt;Large quotes&lt;/h2&gt;
&lt;blockquote class=&quot;lead&quot;&gt;
  &lt;p&gt;You can make a quote “pop out”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;faded-text&quot;&gt;Faded text&lt;/h2&gt;
&lt;p class=&quot;faded&quot;&gt;I’m faded, faded, faded.&lt;/p&gt;</content><author><name>Xinshao Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Hydejack offers a few additional features to markup your markdown. Don’t worry, these are merely CSS classes added with kramdown’s {:...} syntax, so that your content remains compatible with other Jekyll themes.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/example-content-iii.jpg" /></entry><entry><title type="html">Undergraduate graduation</title><link href="http://localhost:4000/projects/2017-07-01-undergraduate-graduation/" rel="alternate" type="text/html" title="Undergraduate graduation" /><published>2017-07-01T00:00:00+01:00</published><updated>2017-07-01T00:00:00+01:00</updated><id>http://localhost:4000/projects/undergraduate-graduation</id><content type="html" xml:base="http://localhost:4000/projects/2017-07-01-undergraduate-graduation/">&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This post is outdated and only included for legacy reasons.
See the &lt;a href=&quot;/docs/&quot; class=&quot;heading flip-title&quot;&gt;Documentation&lt;/a&gt; for up-to-date instructions.&lt;/p&gt;</content><author><name>XinshaoAmosWang</name></author><summary type="html">NOTE: This post is outdated and only included for legacy reasons. See the Documentation for up-to-date instructions.</summary></entry></feed>