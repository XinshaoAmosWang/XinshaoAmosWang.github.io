<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2020-03-04T22:34:11+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Xinshao (Amos) Wang</title><subtitle>&quot;Stay Hungry. Stay Foolish. -- Steve Jobs 2005&quot;. ML/DL/AI Research with applications to CV/NLP, etc
</subtitle><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><entry><title type="html">I Love Learning and Applying Mathematics, Statistics!</title><link href="http://localhost:4000/blogs/2020-03-04-I-love-match/" rel="alternate" type="text/html" title="I Love Learning and Applying Mathematics, Statistics!" /><published>2020-03-04T00:00:00+00:00</published><updated>2020-03-04T00:00:00+00:00</updated><id>http://localhost:4000/blogs/I-love-match</id><content type="html" xml:base="http://localhost:4000/blogs/2020-03-04-I-love-match/">&lt;ol class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#linear-algebra&quot;&gt;Linear algebra&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#probabilistic-view-of-the-world&quot;&gt;Probabilistic view of the world&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimisation&quot;&gt;Optimisation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;linear-algebra&quot;&gt;Linear algebra&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.robots.ox.ac.uk/~davidc/pubs/tt2015_dac1.pdf&quot;&gt;Properties of the Covariance Matrix&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Positive semi-definite&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Eigen vectors and Diagonalisation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Eigen values and Determinant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;probabilistic-view-of-the-world&quot;&gt;Probabilistic view of the world&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Mahalanobis_distance&quot;&gt;Mahalanobis distance&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Mahalanobis distance is proportional, for a normal distribution, to the square root of the negative log likelihood (after adding a constant so the minimum is at zero).&lt;/li&gt;
      &lt;li&gt;This intuitive approach can be made quantitative by defining the normalized distance between the test point and the set to be &lt;code class=&quot;MathJax_Preview&quot;&gt;{\displaystyle {x-\mu } \over \sigma }&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;{\displaystyle {x-\mu } \over \sigma }&lt;/script&gt; . By plugging this into the normal distribution we can derive the probability of the test point belonging to the set.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&quot;&gt;Maximum likelihood estimation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.robots.ox.ac.uk/~davidc/pubs/tt2015_dac1.pdf&quot;&gt;Properties of the Covariance Matrix&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_entropy&quot;&gt;Differential entropy&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://math.stackexchange.com/questions/889425/what-does-determinant-of-covariance-matrix-give&quot;&gt;What does Determinant of Covariance Matrix give&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/89952/why-do-we-use-the-determinant-of-the-covariance-matrix-when-using-the-multivaria&quot;&gt;Why do we use the determinant of the covariance matrix when using the multivariate normal?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;optimisation&quot;&gt;Optimisation&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Concave_function&quot;&gt;Concave function&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Linear algebra Probabilistic view of the world Optimisation</summary></entry><entry><title type="html">Papers Related to My PhD Thesis-Example Weighting in Classification and Distance Metric Learning</title><link href="http://localhost:4000/paperlists/2020-02-24-ThesisRelatedPapers/" rel="alternate" type="text/html" title="Papers Related to My PhD Thesis-Example Weighting in Classification and Distance Metric Learning" /><published>2020-02-24T00:00:00+00:00</published><updated>2020-02-24T00:00:00+00:00</updated><id>http://localhost:4000/paperlists/ThesisRelatedPapers</id><content type="html" xml:base="http://localhost:4000/paperlists/2020-02-24-ThesisRelatedPapers/">&lt;ol class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#distance-metric-learning-learning-to-retrieve&quot;&gt;Learning to Retrieve&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#learning-to-classify&quot;&gt;Learning to Classify &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#others&quot;&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;distance-metric-learning-learning-to-retrieve&quot;&gt;Distance Metric Learning: Learning to Retrieve&lt;/h2&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1910.04115.pdf&quot;&gt;Active Ordinal Querying for Tuplewise Similarity Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1807.03748.pdf&quot;&gt;Representation Learning with
Contrastive Predictive Coding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;learning-to-classify&quot;&gt;Learning to Classify&lt;/h2&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;others&quot;&gt;Others&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;A general and Adaptive Robust Loss Function-CVPR 2019 Best Paper Finalist&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Unsupervised Embedding Learning via Invariant and Spreading Instance Feature-CVPR 2019&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Regularising Deep Neural Networks by Noise: Its Interpretation and Optimisation-NeurIPS 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Toward Robustness against Label Noise in Training Deep Discriminative Neural Networks-NeurIPS 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Selfie: Refurbishing Unclean Samples for Robust Deep Learning-ICML 2019&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Unsupervised Label Noise Modeling and Loss Correction-ICML 2019&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise-NeurIPS 2018&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example-weighting&quot;&gt;Example Weighting&lt;/h2&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/328731166_Weighted_Machine_Learning&quot;&gt;Weighted Machine Learning-Mahdi Hashemi∗, Hassan A. Karimi&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v80/katharopoulos18a.html&quot;&gt;Not All Samples Are Created Equal: Deep Learning with Importance Sampling-Angelos Katharopoulos, Franc¸ois Fleuret, ICML 2018&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;computing the importance score for the whole
dataset is still prohibitive and would render the method
unsuitable for online learning.&lt;/li&gt;
      &lt;li&gt;In order to solve the problem of computing the importance for the whole dataset, we pre-sample a large batch of data points, compute the sampling distribution for that batch and re-sample a smaller batch with replacement.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Learning to Retrieve Learning to Classify Others</summary></entry><entry><title type="html">Learning Bayesian Deep Learning, Uncertainty &amp;amp; Variational Techniques</title><link href="http://localhost:4000/blogs/2020-02-21-learn-bayesian-DL/" rel="alternate" type="text/html" title="Learning Bayesian Deep Learning, Uncertainty &amp; Variational Techniques" /><published>2020-02-21T00:00:00+00:00</published><updated>2020-02-21T00:00:00+00:00</updated><id>http://localhost:4000/blogs/learn-bayesian-DL</id><content type="html" xml:base="http://localhost:4000/blogs/2020-02-21-learn-bayesian-DL/">&lt;ol class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#blogs&quot;&gt;Blogs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#papers-on-theories&quot;&gt;Papers on Theories&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#papers-on-applications&quot;&gt;Papers on Applications&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;what-am-i-working-on-now-discussions-are-welcome&quot;&gt;What am I working on now? Discussions are Welcome!&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;../2020-02-18-code-releasing&quot;&gt;Interpreting &lt;code class=&quot;MathJax_Preview&quot;&gt;p(y\|x)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p(y\|x)&lt;/script&gt; and modelling example weighting&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Going to stop treating &lt;code class=&quot;MathJax_Preview&quot;&gt;p(y\|x)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p(y\|x)&lt;/script&gt; as a classfication confidence metric, since it is determinstic. &lt;code class=&quot;MathJax_Preview&quot;&gt;p(y\|x)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p(y\|x)&lt;/script&gt;  is not for deciding whether certain or uncertain.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;p(y\|x)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p(y\|x)&lt;/script&gt; is good as a metric of whether x matches y, though not a good metric indicating whether x is blur or not.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Utilities of Uncertainties&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;blogs&quot;&gt;Blogs&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.inference.vc/everything-that-works-works-because-its-bayesian-2/&quot;&gt;Everything that Works Works Because it’s Bayesian: Why Deep Nets Generalize?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.facebook.com/yann.lecun/posts/10154058859142143&quot;&gt;Yann LeCun’s Comments&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mlg.eng.cam.ac.uk/yarin/blog_2248.html?fbclid=IwAR1lNokscvPVsGFICXDQBhVa2bweIq-mkft6EfUkj9CR8tAIYJ7mNy3Qag8&quot;&gt;YARIN GAL’s PhD Thesis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;papers-on-theories&quot;&gt;Papers on Theories&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.02142.pdf&quot;&gt;Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning-ICML 2016-YARIN GAL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf&quot;&gt;YARIN GAL’s PhD Thesis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=BJij4yg0Z&quot;&gt;A Bayesian Perspective on Generalization and Stochastic Gradient Descent-ICLR 2018 Google Brain-Samuel L. Smith and Quoc V. Le&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2002.08791.pdf&quot;&gt;Bayesian Deep Learning and a Probabilistic Perspective of Generalization–arXiv 2020 New York University-Andrew Gordon Wilson Pavel Izmailov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.04933.pdf&quot;&gt;Sharp Minima Can Generalize For Deep Nets-ICML 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cbmm.mit.edu/sites/default/files/publications/CBMM-Memo-067.pdf&quot;&gt;Theory of Deep Learning III: Generalization Properties of SGD&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=H1oyRlYgg&quot;&gt;On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima-ICLR 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning&quot;&gt;The Marginal Value of Adaptive Gradient Methods in Machine Learning-NIPS 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.jmlr.org/papers/volume18/17-214/17-214.pdf&quot;&gt;Stochastic Gradient Descent as Approximate Bayesian Inference-JMLR 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v48/mandt16.pdf&quot;&gt;A Variational Analysis of Stochastic Gradient Algorithms-ICML 2016&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1503.02406.pdf&quot;&gt;Deep Learning and the Information Bottleneck Principle&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1912.13480.pdf&quot;&gt;On the Difference Between the Information Bottleneck and the Deep Information Bottleneck&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v80/belghazi18a/belghazi18a.pdf&quot;&gt;Mutual Information Neural Estimation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;papers-on-applications&quot;&gt;Papers on Applications&lt;/h3&gt;

&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Robust_Person_Re-Identification_by_Modelling_Feature_Uncertainty_ICCV_2019_paper.pdf&quot;&gt;Robust Person Re-Identification by Modelling Feature Uncertainty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1904.09658.pdf&quot;&gt;Probabilistic Face Embeddings&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1906.04692v1.pdf&quot;&gt;Rethinking Person Re-Identification with Confidence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.04865.pdf&quot;&gt;Learning Confidence for Out-of-Distribution Detection in Neural Networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=ryiAv2xAZ&quot;&gt;Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Blogs Papers on Theories Papers on Applications</summary></entry><entry><title type="html">AAAI-2020</title><link href="http://localhost:4000/paperlists/2020-02-21-AAAI/" rel="alternate" type="text/html" title="AAAI-2020" /><published>2020-02-21T00:00:00+00:00</published><updated>2020-02-21T00:00:00+00:00</updated><id>http://localhost:4000/paperlists/AAAI</id><content type="html" xml:base="http://localhost:4000/paperlists/2020-02-21-AAAI/">&lt;p class=&quot;message&quot;&gt;:+1: means being highly related to my personal research interest.&lt;/p&gt;

&lt;h2 id=&quot;learning-to-compare-and-retrieve&quot;&gt;Learning to Compare and Retrieve&lt;/h2&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1910.04115.pdf&quot;&gt;Active Ordinal Querying for Tuplewise Similarity Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">:+1: means being highly related to my personal research interest.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/steve-harvey.jpg" /></entry><entry><title type="html">Code Releasing of My Recent Work-Derivative Manipulation</title><link href="http://localhost:4000/blogs/2020-02-18-code-releasing/" rel="alternate" type="text/html" title="Code Releasing of My Recent Work-Derivative Manipulation" /><published>2020-02-18T00:00:00+00:00</published><updated>2020-02-18T00:00:00+00:00</updated><id>http://localhost:4000/blogs/code-releasing</id><content type="html" xml:base="http://localhost:4000/blogs/2020-02-18-code-releasing/">&lt;ol class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;../../my_docs/IMAE_Code_Illustration&quot;&gt;IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude’s Variance Matters&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;../../my_docs/DM_Code_Illustration&quot;&gt;Derivative Manipulation for General Example Weighting&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/XinshaoAmosWang/DerivativeManipulation&quot;&gt;Github Page&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude’s Variance Matters</summary></entry><entry><title type="html">Usefull Common Resources/Tricks</title><link href="http://localhost:4000/blogs/2020-02-17-useful-common-resources/" rel="alternate" type="text/html" title="Usefull Common Resources/Tricks" /><published>2020-02-17T00:00:00+00:00</published><updated>2020-02-17T00:00:00+00:00</updated><id>http://localhost:4000/blogs/useful-common-resources</id><content type="html" xml:base="http://localhost:4000/blogs/2020-02-17-useful-common-resources/">&lt;ol class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#useful-links-on-general-study&quot;&gt;Useful Links on General Study&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#github-configuration-of-local-machine-to-github-remote&quot;&gt;Github: Configuration of local machine to github remote&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gdrive&quot;&gt;GDrive&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#useful-links-on-jekyll-google-adsense-markdown&quot;&gt;Useful links on Jekyll, Google AdSense, Markdown. &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#useful-links-on-travel--insurance&quot;&gt;Useful links on Travel &amp;amp; Insurance.  &lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;replace-string-in-files-recursively&quot;&gt;Replace string in files recursively&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;Simplest way to replace (all files, directory, recursive):
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  find . -type f -not -path '*/\.*' -exec sed -i 's/Previous string/New string/g' {} + 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Note: Sometimes you might need to ignore some hidden files i.e. .git, you can use above command.
If you want to include hidden files use,
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;find . -type f  -exec sed -i 's/Previous string/New string/g' {} +
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;useful-links-on-general-study&quot;&gt;Useful Links on General Study&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Information about probabilistic models of cognition
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://cocosci.princeton.edu/tom/bayes.html&quot;&gt;Tom’s Bayesian reading list&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;message&quot;&gt;…&lt;a href=&quot;http://cocosci.princeton.edu/resources.php&quot;&gt;http://cocosci.princeton.edu/resources.php&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;useful-links-on-jekyll-google-adsense-markdown&quot;&gt;Useful links on Jekyll, Google AdSense, Markdown.&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://mycyberuniverse.com/en-gb/add-google-adsense-to-a-jekyll-website.html&quot;&gt;Add Google AdSense to a Jekyll website&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.lewisgavin.co.uk/Google-Analytics-Adsense/&quot;&gt;AdSense Jekyll + Github&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://jekyllrb.com/docs/variables/&quot;&gt;Jekyll Variables&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://michaelsoolee.com/google-analytics-jekyll/&quot;&gt;Add Google Analytics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;useful-links-on-travel--insurance&quot;&gt;Useful links on Travel &amp;amp; Insurance.&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.britishairways.com/en-gb/executive-club/collecting-avios&quot;&gt;Collecting Avios&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://uk.virginmoney.com/virgin/travel-insurance/whats-covered.jsp&quot;&gt;Virgin: What’s covered&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.aig.com.cn/individuals/travel-insurance?utm_source=baidu&amp;amp;utm_campaign=%E9%80%9A%E7%94%A8%E8%AF%8D%2D%E6%97%85%E8%A1%8C%E9%99%A9&amp;amp;utm_adgroup=%E9%80%9A%E7%94%A8%2D%E6%97%85%E6%B8%B8%E9%99%A9&amp;amp;utm_term=%E6%97%85%E8%A1%8C%E4%BF%9D%E9%99%A9&amp;amp;utm_medium=search%5Fcpc&amp;amp;utm_channel=baidu%5Fpc&amp;amp;utm_content=tyc&amp;amp;bd_vid=10708153713933454488&quot;&gt;AIG&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.allianz360.com/?media=d4cd86c5e9444316994e5a2c00fa9cd6&amp;amp;type=1&quot;&gt;京东安联&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.aerlingus.com/html/flightSearchResult.html#/fareType=ONEWAY&amp;amp;fareCategory=ECONOMY&amp;amp;promoCode=&amp;amp;numAdults=1&amp;amp;numChildren=0&amp;amp;numInfants=0&amp;amp;groupBooking=false&amp;amp;sourceAirportCode_0=DUB&amp;amp;destinationAirportCode_0=LHR&amp;amp;departureDate_0=2019-10-19&amp;amp;flightCode_0=EI168&quot;&gt;Aer Lingus: Dublin T2 =&amp;gt; London Heathrow&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gdrive&quot;&gt;GDrive&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/gdrive-org/gdrive&quot;&gt;GDrive Github&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/gdrive-org/gdrive/issues/116&quot;&gt;List Folder, Root&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://askubuntu.com/questions/867284/using-gdrive-to-download-entire-folder&quot;&gt;Download entire folder&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.linuxandubuntu.com/home/google-drive-cli-client-for-linux&quot;&gt;How to use GDrive in linux?&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;github-configuration-of-local-machine-to-github-remote&quot;&gt;Github: Configuration of local machine to github remote&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://help.github.com/en/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key&quot;&gt;Local: Generating a new ssh key&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://help.github.com/en/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#adding-your-ssh-key-to-the-ssh-agent&quot;&gt;Local: Adding your new SSH key to the ssh-agent&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://help.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account&quot;&gt;Remote: Adding your new SSH key to your GitHub account&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/XinshaoAmosWang/Deep-Metric-Embedding/blob/master/common_git.md&quot;&gt;Common commands&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Useful Links on General Study Github: Configuration of local machine to github remote GDrive Useful links on Jekyll, Google AdSense, Markdown. Useful links on Travel &amp;amp; Insurance.</summary></entry><entry><title type="html">arXiv-2020</title><link href="http://localhost:4000/paperlists/2020-02-16-arXiv/" rel="alternate" type="text/html" title="arXiv-2020" /><published>2020-02-16T00:00:00+00:00</published><updated>2020-02-16T00:00:00+00:00</updated><id>http://localhost:4000/paperlists/arXiv</id><content type="html" xml:base="http://localhost:4000/paperlists/2020-02-16-arXiv/">&lt;p class=&quot;message&quot;&gt;:+1: means being highly related to my personal research interest.&lt;/p&gt;

&lt;h2 id=&quot;foundation-of-deep-learning&quot;&gt;Foundation of Deep Learning&lt;/h2&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2002.09046.pdf&quot;&gt;Neural Bayes: A Generic Parameterization Method for Unsupervised Representation Learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2002.05709.pdf&quot;&gt;A Simple Framework for Contrastive Learning of Visual Representations&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Data augmentation: composition of data augmentations plays a critical role in defining effective predictive tasks;&lt;/li&gt;
      &lt;li&gt;Auxiliary transformation:  introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations;&lt;/li&gt;
      &lt;li&gt;Larger batch size and more training steps: contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning.&lt;/li&gt;
      &lt;li&gt;Results: By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1911.09976.pdf&quot;&gt;Instance Cross Entropy for Deep Metric Learning&lt;/a&gt; and its application in SimCLR-A Simple Framework for Contrastive Learning of Visual Representations&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;I am very glad to highlight that:  our proposed ICE is simple and effective, which has also been demonstrated in recent work SimCLR, in the context of self-supervised learning: A Simple Framework for Contrastive Learning of Visual Representations&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Its loss expression NT-Xent (the normalized temperature-scaled cross entropy loss) is a fantastic application of our recently proposed Instance Cross Entropy for Deep Metric Learning,  in the context of self-supervised learnining. I am very excited about this.
        &lt;ul&gt;
          &lt;li&gt;#InstanceCrossEntropy #TemperatureScaling #RepresentationLearning&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/337485049_Instance_Cross_Entropy_for_Deep_Metric_Learning/comments&quot;&gt;Research Gate&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=BJeguTEKDB&amp;amp;noteId=txrrkCL-sXhttps://openreview.net/forum?id=BJeguTEKDB&amp;amp;noteId=txrrkCL-sX&quot;&gt;Open Review&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/f4x1sh/r_instance_cross_entropy_for_deep_metric_learning/&quot;&gt;Reddit&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1904.03436.pdf&quot;&gt;Unsupervised Embedding Learning via Invariant and Spreading Instance Feature&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Unsupervised Embedding Learning via Invariant and SpreadingInstance Feature is even closer, also in the context of self-supervised learning, maximising the agreement over augmentations of one instance.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1911.09976.pdf&quot;&gt; Instance Cross Entropy for Deep Metric Learning&lt;/a&gt; is in the context of supervised discriminative representation learning, maximising the agreement over augmentaions of multiple images i.e. a class.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://xinshaoamoswang.github.io/Papers/AnomalyAndRegularisation/#iclr-2019-learning-deep-representations-by-mutual-information-estimation-and-maximization&quot;&gt;ICLR 2019: Learning deep representations by mutual information estimation and maximization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">:+1: means being highly related to my personal research interest.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/steve-harvey.jpg" /></entry><entry><title type="html">Paper notes on Anomalies&amp;amp;Regularisation</title><link href="http://localhost:4000/blogs/2020-02-15-anomalies-regularisation/" rel="alternate" type="text/html" title="Paper notes on Anomalies&amp;Regularisation" /><published>2020-02-15T00:00:00+00:00</published><updated>2020-02-15T00:00:00+00:00</updated><id>http://localhost:4000/blogs/anomalies-regularisation</id><content type="html" xml:base="http://localhost:4000/blogs/2020-02-15-anomalies-regularisation/">&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;/Papers/AnomalyAndRegularisation/&quot;&gt;Paper notes on Anomalies&amp;amp;Regularisation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Paper notes on Anomalies&amp;amp;Regularisation</summary></entry><entry><title type="html">Notes on Core ML Techniques</title><link href="http://localhost:4000/blogs/2020-02-14-Core-machine-learning-topics/" rel="alternate" type="text/html" title="Notes on Core ML Techniques" /><published>2020-02-14T00:00:00+00:00</published><updated>2020-02-14T00:00:00+00:00</updated><id>http://localhost:4000/blogs/Core-machine-learning-topics</id><content type="html" xml:base="http://localhost:4000/blogs/2020-02-14-Core-machine-learning-topics/">&lt;ol class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#kullback-leibler-divergence&quot;&gt;Kullback-Leibler Divergence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-the-main-difference-between-gan-and-autoencoder&quot;&gt;What is the main difference between GAN and autoencoder&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#whats-the-difference-between-a-variational-autoencoder-vae-and-an-autoencoder&quot;&gt;What’s the difference between a Variational Autoencoder (VAE) and an Autoencoder?&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#knowledge-distillation&quot;&gt;Knowledge Distillation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#confidence-penalty--label-smoothing--ouput-regularisation&quot;&gt;Confidence penalty &amp;amp; Label Smoothing &amp;amp;&amp;amp; Ouput Regularisation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncertainty&quot;&gt;Uncertainty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#long-tailed-recognition&quot;&gt;Long-tailed Recognition-Sample Imbalance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#meta-learning&quot;&gt;Meta-learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ensemble-methods&quot;&gt;Ensemble methods&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;knowledge-distillation&quot;&gt;Knowledge Distillation&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1503.02531.pdf&quot;&gt;Distilling the Knowledge in a Neural Network&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Knowledge definition&lt;/strong&gt;: A more
abstract view of the knowledge, that frees it from any particular instantiation, is that it is a learned mapping from input vectors to output vectors.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;An obvious way to &lt;strong&gt;transfer the generalization ability of the cumbersome model to a small model&lt;/strong&gt; is
to use the class probabilities produced by the cumbersome model as &lt;strong&gt;“soft targets” for training the
small model.&lt;/strong&gt; When the soft targets
have high entropy, they provide much more information per training case than hard targets and much
less variance in the gradient between training cases, so the small model can often be trained on much
less data than the original cumbersome model and using a much higher learning rate.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;#ensemble-methods&quot;&gt;A very simple way to improve the performance of almost any machine learning
algorithm is to train many different models on the same data and then to average
their predictions&lt;/a&gt; =&amp;gt; cumbersome and may be too computationally expensive&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Compress/distill the knowledge in an ensemble into a single model&lt;/strong&gt; which is much easier to deploy (distilling the knowledge in an ensemble of models into a single model);&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;confidence-penalty--label-smoothing--ouput-regularisation&quot;&gt;Confidence penalty &amp;amp; Label Smoothing &amp;amp;&amp;amp; Ouput Regularisation&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=HkCjNI5ex&quot;&gt;Regularizing Neural Networks by Penalizing Confident Output Distributions&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Output regularisation&lt;/strong&gt;: Regularizing the output distribution of large, deep neural networks has largely been unexplored.  Output regularization has the property that it is invariant
to the parameterization of the underlying neural network.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Knowledge definition&lt;/strong&gt;: To motivate output regularizers, we can view the knowledge of a model as the conditional distribution it produces over outputs given an input (Hinton et al., 2015) as opposed to the learned values
of its parameters.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Distillation definition:&lt;/strong&gt; explicitly training a small network to assign the same probabilities to incorrect
classes as a large network or ensemble of networks that generalizes well.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Two output regularizers&lt;/strong&gt;:
        &lt;ul&gt;
          &lt;li&gt;A maximum entropy based confidence penalty;&lt;/li&gt;
          &lt;li&gt;Label smoothing (uniform and unigram).&lt;/li&gt;
          &lt;li&gt;We connect a maximum entropy based confidence penalty to label smoothing through the direction of the KL divergence.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;ANNEALING AND THRESHOLDING THE CONFIDENCE PENALTY
        &lt;ul&gt;
          &lt;li&gt;Suggesting a confidence penalty
that is weak at the beginning of training and strong near convergence.&lt;/li&gt;
          &lt;li&gt;Only penalize output distributions when they are below a certain entropy threshold&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Label/Objective smoothing:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Smoothing the labels with a uniform distribution-&lt;a href=&quot;https://arxiv.org/pdf/1512.00567.pdf&quot;&gt;Rethinking the Inception Architecture&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Smooth the labels with a teacher model &lt;a href=&quot;https://arxiv.org/pdf/1503.02531.pdf&quot;&gt;Distilling, Hinton et al., 2015&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Smooth the labels with the model’s own distribution-&lt;a href=&quot;https://arxiv.org/pdf/1412.6596.pdf&quot;&gt;TRAINING DEEP NEURAL NETWORKS
ON NOISY LABELS WITH BOOTSTRAPPING (Reed et al., 2014)&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Adding label noise simply-&lt;a href=&quot;https://www.zpascal.net/cvpr2016/Xie_DisturbLabel_Regularizing_CNN_CVPR_2016_paper.pdf&quot;&gt;Disturblabel: Regularizing cnn on the loss layer–CVPR 2016&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Distillation and self-distillation both
regularize a network by incorporating information about the ratios between incorrect classes.&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Label-Smoothing Regularization proposed in &lt;a href=&quot;https://arxiv.org/pdf/1512.00567.pdf&quot;&gt;Rethinking the Inception Architecture for Computer Vision&lt;/a&gt;-A mechanism for encouraging the model to be less confident.
    &lt;ul&gt;
      &lt;li&gt;Over-fitting&lt;/li&gt;
      &lt;li&gt;Reduces the ability of the model to &lt;strong&gt;adapt: bounded gradient&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Virtual adversarial training (VAT) &lt;a href=&quot;https://arxiv.org/pdf/1507.00677.pdf&quot;&gt;Distributional
smoothing by virtual adversarial examples&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Another promising smoothing regularizer. However, it has multiple hyperparameters, significantly more computation in grid-searching&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;uncertainty&quot;&gt;Uncertainty&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://xinshaoamoswang.github.io/Papers/AnomalyAndRegularisation/#neurips-2018-predictive-uncertainty-estimation-via-prior-networks&quot;&gt;NeurIPS 2018: Predictive Uncertainty Estimation via Prior Networks&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ermongroup.github.io/cs228-notes/extras/vae/&quot;&gt;The variational auto-encoder&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://papers.nips.cc/paper/7850-information-constraints-on-auto-encoding-variational-bayes.pdf&quot;&gt;Information Constraints on Auto-Encoding Variational Bayes-NeurIPS 2018&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2002.07217.pdf&quot;&gt;Decision-Making with Auto-Encoding Variational Bayes&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1312.6114.pdf&quot;&gt;Auto-Encoding Variational Bayes-ICLR 2014&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://openreview.net/forum?id=HyxQzBceg&quot;&gt;Deep Variational Information Bottleneck-ICLR2017&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.03454.pdf&quot;&gt;Deep Variational Canonical Correlation Analysis&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/physics/0004057.pdf&quot;&gt;The information bottleneck (IB) principle–The information
bottleneck method&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ermongroup.github.io/cs228-notes/&quot;&gt;CS 228 - Probabilistic Graphical Models&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1906.04692.pdf&quot;&gt;Rethinking Person Re-Identification with Confidence&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;long-tailed-recognition&quot;&gt;Long-tailed Recognition&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/references/pdf?id=nHObduxXz&quot;&gt;DECOUPLING REPRESENTATION AND CLASSIFIER
FOR LONG-TAILED RECOGNITION-ICLR2020&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Representation Learning: We first train models to learn representations with different sampling strategies, including the standard instance-based sampling, class-balanced sampling and a mixture of them.&lt;/li&gt;
      &lt;li&gt;Classification: We study three different basic approaches to obtain a classifier with balanced decision boundaries, on top of the learned representations.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;meta-learning&quot;&gt;Meta-learning&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/f6e25t/r_confusion_on_the_definition_of_metalearning/&quot;&gt;Confusion on the definition of Meta-learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../../my_docs/few-shot&quot;&gt;Few-shot Learning is an instantiation of Meta-learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_MetaCleaner_Learning_to_Hallucinate_Clean_Representations_for_Noisy-Labeled_Visual_Recognition_CVPR_2019_paper.pdf&quot;&gt;MetaCleaner: Learning to Hallucinate Clean Representations for Noisy-Labeled Visual Recognition&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Noisy Weighting: estimate the confidence scores of all the images in the noisy subset;  &lt;strong&gt;MetaCleaner compares these representations in the feature space =&amp;gt; discover relations between images =&amp;gt; generate the confidence score of each image in the subset.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Clean Hallucinating: to hallucinate a `clean‘ representation of a class from the noisy subset, by summarizing the noisy images with their confidence scores;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;MetaCleaner as a new layer before classifier: batch size $K \times N =&amp;gt; K$, $K$ categories, $N$ images per class in the batch&lt;/strong&gt;.&lt;/li&gt;
      &lt;li&gt;Different from prototypical network, our MetaCleaner mainly develops a robust classifier to reduce confusion of noisy labels. Hence, it adaptively uses the weighted prototype as a ‘clean’ representation to generalize softmax classifier, instead of using the mean prototype to construct a metric classifier for low-shot learning.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Why is this called meta-learning?&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Learning_to_Learn_From_Noisy_Labeled_Data_CVPR_2019_paper.pdf&quot;&gt;Learning to Learn From Noisy Labeled Data-CVPR 2019&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/LiJunnan1992/MLNT/issues/1&quot;&gt;My Understanding: https://github.com/LiJunnan1992/MLNT/issues/1&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;Iteratively Improve the Teacher/Oracle == Soft Target&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Meta-obejctive-training/testing:&lt;/strong&gt;   The meta-training sees synthetic noisy training examples. After training on them, the meta-testing evaluates its consistency with oracle and aims to maximise the consistency, i.e., making it unaffected after seeing synthetic noise.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/bws5iv/r_cvpr_2019_noisetolerant_training_work_learning/&quot;&gt;Reddit Analysis&lt;/a&gt;: Extremely complex in practice. However, the ideas are interesting and novel.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1803.09050.pdf&quot;&gt;Learning to Reweight Examples for Robust Deep Learning-ICML 2018&lt;/a&gt;- Simultaneously minimize the loss on &lt;strong&gt;a clean unbiased validation set&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Meta-objective&lt;/strong&gt;: a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;:  Suppose that &lt;strong&gt;a pair of training and validation examples are very similar&lt;/strong&gt;, and they also provide
&lt;strong&gt;similar gradient directions&lt;/strong&gt;, then this training example is
helpful and should be up-weighted, and conversely, if they
provide &lt;strong&gt;opposite gradient directions&lt;/strong&gt;, this training example
is harmful and should be downweighed.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/8467-meta-weight-net-learning-an-explicit-mapping-for-sample-weighting.pdf&quot;&gt;Meta-Weight-Net: Learning an Explicit Mapping
For Sample Weighting-NeurIPS 2019&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;The major difference with &lt;a href=&quot;https://arxiv.org/pdf/1803.09050.pdf&quot;&gt;Learning to Reweight Examples&lt;/a&gt; is that the weights are implicitly learned there, without an explicit weighting function.
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;I am skeptical and not convinced here!&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ensemble-methods&quot;&gt;Ensemble methods&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=7F08BF5ADDA7E8BB9D5F40EA4241AD81?doi=10.1.1.228.2236&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Ensemble methods in machine learning&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Ensemble methods are learning algorithms that construct &lt;strong&gt;a set of classifiers&lt;/strong&gt; and then classify new data points by taking &lt;strong&gt;a weighted vote of their predictions.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;The original ensemble method is &lt;strong&gt;Bayesian averaging&lt;/strong&gt; but more recent algorithms include error correcting output coding, Bagging and boosting. &lt;strong&gt;This paper reviews these methods and explains why ensembles can often perform better than any single classifier.&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Bayesian Voting Enumerating the Hypotheses.&lt;/li&gt;
          &lt;li&gt;Bagging: Bagging presents the learning algorithm with a training set that consists of a sample of $m$ training examples drawn randomly with replacement from the original training set of $m$ items.&lt;/li&gt;
          &lt;li&gt;…&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;kullback-leibler-divergence&quot;&gt;Kullback-Leibler Divergence&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained&quot;&gt;How to approximate our data (choose a parameterized distribution =&amp;gt; optimise its parameters): KL Divergence helps us to measure just how much information we lose when we choose an approximation compared with our observations.&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;The most important metric in information theory is called &lt;strong&gt;Entropy&lt;/strong&gt;, typically denoted as $\mathbf{H}$. The definition of Entropy for a probability distribution is: $\mathbf{H}=-\sum_{i=1}^{n} p(\mathbf{x}_i) \log p(\mathbf{x}_i) $.&lt;/li&gt;
      &lt;li&gt;If we use $\log_2$ for our calculation we can interpret entropy as “the minimum number of bits it would take us to encode our information”.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8&quot;&gt;Intuitive Guide to Understanding KL Divergence&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;What is a distributin?&lt;/li&gt;
      &lt;li&gt;What is an event?&lt;/li&gt;
      &lt;li&gt;Problem we’re trying to solve: choose a parameterized distribution =&amp;gt; optimise its parameters): KL Divergence helps us to measure just how much information we lose when we choose an approximation compared with our observations.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;what-is-the-main-difference-between-gan-and-autoencoder&quot;&gt;What is the main difference between GAN and autoencoder?&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://datascience.stackexchange.com/a/55094&quot;&gt;An autoencoder learns to represent some input information very efficiently, and subsequently how to reconstruct the input from it’s compressed form.&lt;/a&gt;
  ~ :) ~&lt;a href=&quot;https://qr.ae/TzM5Mv&quot;&gt;An autoencoder compresses its input down to a vector - with much fewer dimensions than its input data, and then transforms it back into a tensor with the same shape as its input over several neural net layers. They’re trained to reproduce their input, so it’s kind of like learning a compression algorithm for that specific dataset.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://datascience.stackexchange.com/a/55094&quot;&gt;A GAN uses an adversarial feedback loop to learn how to generate some information that “seems real” (i.e. looks the same/sounds the same/is otherwise indistinguishable from some real data)&lt;/a&gt; ~ :) ~ &lt;a href=&quot;https://qr.ae/TzM5Mv&quot;&gt;Instead of being given a bit of data as input, it’s given a small vector of random numbers. The generator network tries to transform this little vector into a realistic sample from the training data. The discriminator network then takes this generated sample(and some real samples from the dataset) and learns to guess whether the samples are real or fake.&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://qr.ae/TzM5Mv&quot;&gt;Another difference: while they both fall under the umbrella of unsupervised learning, they are different approaches to the problem. A GAN is a generative model - it’s supposed to learn to generate realistic &lt;em&gt;new&lt;/em&gt; samples of a dataset. Variational autoencoders are generative models, but normal “vanilla” autoencoders just reconstruct their inputs and can’t generate realistic new samples.&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://qr.ae/TzMSyS&quot;&gt;Autoencoders learn a given distribution comparing its input to its output, this is good for learning hidden representations of data, but is pretty bad for generating new data. Mainly because we learn an averaged representation of the data thus the output becomes pretty blurry.
  Generative Adversarial Networks take an entirely different approach. They use another network (so-called Discriminator) to measure the distance between the generated and the real data.
  The main advantage of GANs over Autoencoders in generating data is that they can be conditioned by different inputs. For example, you can learn the mapping between two domains: satellite images to google maps [1] . Or you can teach the generator to reproduce several classes of data: generating the MNIST dataset[2] .
  &lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.keras.io/building-autoencoders-in-keras.html&quot;&gt; Building Autoencoders in Keras&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/gans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&quot;&gt;Coding: GANs vs. Autoencoders: Comparison of Deep Generative Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;whats-the-difference-between-a-variational-autoencoder-vae-and-an-autoencoder&quot;&gt;What’s the difference between a Variational Autoencoder (VAE) and an Autoencoder?&lt;/h3&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf&quot;&gt;Intuitively Understanding Variational Autoencoders – Towards Data Science by Irhum Shafkat.&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class=&quot;quora-content-embed&quot; data-name=&quot;Whats-the-difference-between-a-Variational-Autoencoder-VAE-and-an-Autoencoder/answer/Vishal-Sharma-154&quot;&gt;Read &lt;a class=&quot;quora-content-link&quot; data-width=&quot;560&quot; data-height=&quot;260&quot; href=&quot;https://www.quora.com/Whats-the-difference-between-a-Variational-Autoencoder-VAE-and-an-Autoencoder/answer/Vishal-Sharma-154&quot; data-type=&quot;answer&quot; data-id=&quot;66853410&quot; data-key=&quot;a5099035f08fbac1ed45a4bb7a1c5d2c&quot; load-full-answer=&quot;False&quot; data-embed=&quot;trhonms&quot;&gt;&lt;a href=&quot;https://www.quora.com/Vishal-Sharma-154&quot;&gt;Vishal Sharma&lt;/a&gt;'s &lt;a href=&quot;/Whats-the-difference-between-a-Variational-Autoencoder-VAE-and-an-Autoencoder?top_ans=66853410&quot;&gt;answer&lt;/a&gt; to &lt;a href=&quot;/Whats-the-difference-between-a-Variational-Autoencoder-VAE-and-an-Autoencoder&quot; ref=&quot;canonical&quot;&gt;&lt;span class=&quot;rendered_qtext&quot;&gt;What's the difference between a Variational Autoencoder (VAE) and an Autoencoder?&lt;/span&gt;&lt;/a&gt;&lt;/a&gt; on &lt;a href=&quot;https://www.quora.com&quot;&gt;Quora&lt;/a&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;https://www.quora.com/widgets/content&quot;&gt;&lt;/script&gt;&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.keras.io/building-autoencoders-in-keras.html&quot;&gt; Building Autoencoders in Keras&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://distill.pub/2017/aia/&quot;&gt;Using Artificial Intelligence to Augment Human Intelligence&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://efrosgans.eecs.berkeley.edu/CVPR18_slides/VAE_GANS_by_Rosca.pdf&quot;&gt;VAEs and GANs
Mihaela Rosca&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://syncedreview.com/2019/06/06/going-beyond-gan-new-deepmind-vae-model-generates-high-fidelity-human-faces/&quot;&gt;Going Beyond GAN? New DeepMind VAE Model Generates High Fidelity Human Faces&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">Kullback-Leibler Divergence What is the main difference between GAN and autoencoder What’s the difference between a Variational Autoencoder (VAE) and an Autoencoder?</summary></entry><entry><title type="html">ICLR-2020</title><link href="http://localhost:4000/paperlists/2020-01-02-ICLR/" rel="alternate" type="text/html" title="ICLR-2020" /><published>2020-01-02T00:00:00+00:00</published><updated>2020-01-02T00:00:00+00:00</updated><id>http://localhost:4000/paperlists/ICLR</id><content type="html" xml:base="http://localhost:4000/paperlists/2020-01-02-ICLR/">&lt;p class=&quot;message&quot;&gt;:+1: means being highly related to my personal research interest.&lt;/p&gt;

&lt;h2 id=&quot;foundation-of-deep-learning&quot;&gt;Foundation of Deep Learning&lt;/h2&gt;
&lt;ul class=&quot;message&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=B1g8VkHFPH&quot;&gt;Rethinking the Hyperparameters for Fine-tuning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=BJgnXpVYwS&quot;&gt;WHY GRADIENT CLIPPING ACCELERATES TRAINING:
A THEORETICAL JUSTIFICATION FOR ADAPTIVITY&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xinshao (Amos) Wang</name><email>xwang at qub dot ac dot uk xwang at qub dot ac dot uk</email></author><summary type="html">:+1: means being highly related to my personal research interest.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/steve-harvey.jpg" /></entry></feed>