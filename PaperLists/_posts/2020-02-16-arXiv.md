---
layout: post
title: arXiv-2020
description: >
  
image: /assets/img/blog/steve-harvey.jpg
comment: true
---

:+1: means being highly related to my personal research interest. 
{:.message}


## Foundation of Deep Learning 
* [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf)
    * Data augmentation: composition of data augmentations plays a critical role in defining effective predictive tasks;
    * Auxiliary transformation:  introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations;
    * Larger batch size and more training steps: contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning.
    * Results: By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy.


* [Instance Cross Entropy for Deep Metric Learning](https://arxiv.org/pdf/1911.09976.pdf) and its application in SimCLR-A Simple Framework for Contrastive Learning of Visual Representations

    * I am very glad to highlight that:  our proposed ICE is simple and effective, which has also been demonstrated in recent work SimCLR, in the context of self-supervised learning: A Simple Framework for Contrastive Learning of Visual Representations

    * Its loss expression NT-Xent (the normalized temperature-scaled cross entropy loss) is a fantastic application of our recently proposed Instance Cross Entropy for Deep Metric Learning,  in the context of self-supervised learnining. I am very excited about this.
        * #InstanceCrossEntropy #TemperatureScaling #RepresentationLearning
    * [Research Gate](https://www.researchgate.net/publication/337485049_Instance_Cross_Entropy_for_Deep_Metric_Learning/comments)
    * [Open Review](https://openreview.net/forum?id=BJeguTEKDB&noteId=txrrkCL-sXhttps://openreview.net/forum?id=BJeguTEKDB&noteId=txrrkCL-sX)
    * [Reddit](https://www.reddit.com/r/MachineLearning/comments/f4x1sh/r_instance_cross_entropy_for_deep_metric_learning/)
* [Unsupervised Embedding Learning via Invariant and Spreading Instance Feature](https://arxiv.org/pdf/1904.03436.pdf)
    * Unsupervised Embedding Learning via Invariant and SpreadingInstance Feature is even closer, also in the context of self-supervised learning, maximising the agreement over augmentations of one instance.
    * [ Instance Cross Entropy for Deep Metric Learning](https://arxiv.org/pdf/1911.09976.pdf) is in the context of supervised discriminative representation learning, maximising the agreement over augmentaions of multiple images i.e. a class.
{:.message}




